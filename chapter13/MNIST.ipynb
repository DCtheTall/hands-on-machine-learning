{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlgMFaMI8M12",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 13: Convolutional Neural Networks\n",
        "\n",
        "## Exercise 7\n",
        "\n",
        "Build your own CNN and try to achieve the highest possible accuracy on MNIST.\n",
        "\n",
        "## Solution\n",
        "\n",
        "For this exercise, I am going to implement a simplified version of LeNet-5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkg36BK18LoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLX3TzRJRL5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading MNIST dataset.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28, 28, 1) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28, 28, 1) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbqQ8u42RNLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the TensorFlow graph.\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "batch_size = 50\n",
        "n_batches = len(X_train) // batch_size\n",
        "\n",
        "with graph.as_default():\n",
        "  with tf.device('/cpu:0'):\n",
        "    training = tf.placeholder_with_default(False, shape=())\n",
        "  with tf.device('/gpu:0'):\n",
        "    X = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name='X')\n",
        "    X_padded = tf.pad(X, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]],\n",
        "                      name='X_padded')\n",
        "    y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
        "\n",
        "    C1 = tf.math.tanh(tf.layers.conv2d(X_padded, filters=6, kernel_size=5,\n",
        "                                       strides=[1,1], name='C1'))\n",
        "    S2 = tf.math.tanh(tf.nn.avg_pool(C1, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                                     name='S2', padding='VALID'))\n",
        "    C3 = tf.math.tanh(tf.layers.conv2d(S2, filters=16, kernel_size=5,\n",
        "                                      strides=[1,1], name='C3'))\n",
        "    S4 = tf.math.tanh(tf.nn.avg_pool(C3, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                                     name='S4', padding='VALID'))\n",
        "    C5 = tf.math.tanh(tf.layers.conv2d(S4, filters=120, kernel_size=5,\n",
        "                                      strides=[1,1], name='C5'))\n",
        "    F6 = tf.squeeze(\n",
        "        tf.squeeze(\n",
        "            tf.layers.dense(C5, 84, activation=tf.math.tanh, name='F6'),\n",
        "            axis=1),\n",
        "        axis=1)\n",
        "    logits = tf.layers.dense(F6, 10, name='logits')\n",
        "\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                              logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "  with tf.device('/cpu:0'):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "    rnd_queue = tf.RandomShuffleQueue(capacity=len(X_train),\n",
        "                                      min_after_dequeue=0,\n",
        "                                      dtypes=[tf.float32, tf.int32],\n",
        "                                      shapes=[(28, 28, 1), ()])\n",
        "    enqueue_op = rnd_queue.enqueue_many([X, y])\n",
        "    dequeue_op = rnd_queue.dequeue_up_to(batch_size)\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOjnKrx1huCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2865bf52-41a4-4fb5-d99b-0d083823297f"
      },
      "source": [
        "# Training the model using early stopping.\n",
        "\n",
        "n_epochs = 100\n",
        "model_path = 'my_model.ckpt'\n",
        "\n",
        "with graph.as_default():\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    best_loss = None\n",
        "    rounds_since_best_loss = 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      sess.run(enqueue_op, feed_dict={X: X_train, y: y_train, training: True})\n",
        "      for _ in range(n_batches):\n",
        "        X_batch, y_batch = sess.run(dequeue_op)\n",
        "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "      if epoch == 0:\n",
        "        best_loss = loss.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        saver.save(sess, model_path)\n",
        "      elif epoch % 5 == 0:\n",
        "        loss_val = loss.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        if loss_val < best_loss:\n",
        "          best_loss = loss_val\n",
        "          rounds_since_best_loss = 0\n",
        "        else:\n",
        "          rounds_since_best_loss += 1\n",
        "          if rounds_since_best_loss == 4:\n",
        "            print('Early stopping at epoch:', epoch+1)\n",
        "            break\n",
        "      else:\n",
        "        saver.save(sess, model_path)\n",
        "\n",
        "    saver.restore(sess, model_path)\n",
        "    train_acc_val = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
        "    test_acc_val = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "\n",
        "    print('Model training complete.')\n",
        "    print('Training epochs until convergence:', epoch+1)\n",
        "    print('Training set accuracy:', train_acc_val)\n",
        "    print('Test set accuracy:', test_acc_val)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stopping at epoch: 26\n",
            "INFO:tensorflow:Restoring parameters from my_model.ckpt\n",
            "Model training complete.\n",
            "Training epochs until convergence: 26\n",
            "Training set accuracy: 0.99841815\n",
            "Test set accuracy: 0.9872\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}