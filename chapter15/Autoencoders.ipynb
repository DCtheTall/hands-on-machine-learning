{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2Yqnh1gXS8",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 15: Autoencoders\n",
        "\n",
        "Autoencoders are an unsupervised neural network architecture who are tasked with reproducing their input. They do so by learning how to encode their inputs using hidden layers that are _smaller_ than the input layer. This forces the model to learn an efficient representation of the data, called _codings_.\n",
        "\n",
        "Below is some setup code which the author uses for the code throughout the chapter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLsyTnsMgU2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Plot styling.\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Code for saving figures.\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"autoencoders\"\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, 'images', '{}.png'.format(fig_id))\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl0abSFRt-yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image, shape=[28, 28]):\n",
        "    plt.imshow(image.reshape(shape), cmap='Greys', interpolation='nearest')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olJpqlG4KYMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtkKk8HxGzL5",
        "colab_type": "text"
      },
      "source": [
        "## Performing PCA with an Undercomplete Linear Autoencoder\n",
        "\n",
        "An autoencoder with only linear activation functions that uses MSE as the loss function can be shown to be equivalent to PCA (Chapter 8)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQXLRrN3Gymx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a 3D dataset.\n",
        "\n",
        "import numpy.random as rnd\n",
        "\n",
        "rnd.seed(42)\n",
        "m = 200\n",
        "w1, w2 = 0.1, 0.3\n",
        "noise = 0.1\n",
        "\n",
        "angles = rnd.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "data = np.empty((m, 3))\n",
        "data[:, 0] = np.cos(angles) + (np.sin(angles) / 2) + (noise * rnd.randn(m) / 2)\n",
        "data[:, 1] = (np.sin(angles) * 0.7) + (noise * rnd.randn(m) / 2)\n",
        "data[:, 2] = (data[:, 0] * w1) + (data[:, 1] * w2) + (noise * rnd.randn(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4N4ceT_H1-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data with StandardScaler.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(data[:100])\n",
        "X_test = scaler.transform(data[100:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKrj7NTVIl1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model graph.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 3\n",
        "n_hidden = 2\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "hidden = tf.layers.dense(X, n_hidden)\n",
        "outputs = tf.layers.dense(hidden, n_outputs)\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(reconstruction_loss)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWZb2YAsJoK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the autoencoder.\n",
        "\n",
        "n_iterations = 100\n",
        "codings = hidden\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for i in range(n_iterations):\n",
        "    training_op.run(feed_dict={X: X_train})\n",
        "  codings_val = codings.eval(feed_dict={X: X_test})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUAIdt0oKDO0",
        "colab_type": "code",
        "outputId": "1385b15c-7e8c-4672-fe52-ea5bf22e1219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Plotting the figure.\n",
        "\n",
        "fig = plt.figure(figsize=(4,3))\n",
        "plt.plot(codings_val[:,0], codings_val[:, 1], 'b.')\n",
        "plt.xlabel('$z_1$', fontsize=18)\n",
        "plt.ylabel('$z_2$', fontsize=18, rotation=0)\n",
        "save_fig('linear_autoencoder_pca_plot')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure linear_autoencoder_pca_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAADQCAYAAADcQn7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc0YcMeLd8PE",
        "colab_type": "text"
      },
      "source": [
        "## Stacked Autoencoders\n",
        "\n",
        "Autoencoders with multiple hidden layers are called _stacked autoencoders_ (or _deep autoencoders_). You must be wary that if the autoencoder is too deep, it may just learn how to reproduce the training set, leading to overfitting. Below is a TensorFlow implementation of a stacked autoencoder with 3 hidden layers used for generating handwritten digits using the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGCKRSUzfNG9",
        "colab_type": "code",
        "outputId": "a62267c9-756c-463f-ef9e-0e0674b21d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# Downloading the data.\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuAyScFRf3Cd",
        "colab_type": "text"
      },
      "source": [
        "### Train all layers at once\n",
        "\n",
        "The example below trains all of the hidden layers of the stacked autoencoder at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0E4zltAf2iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model graph.\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "l2_reg = 0.0001\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "dense = partial(tf.layers.dense, activation=tf.nn.relu,\n",
        "                kernel_initializer=he_init, kernel_regularizer=regularizer)\n",
        "\n",
        "hidden1 = dense(X, n_hidden1)\n",
        "hidden2 = dense(hidden1, n_hidden2)\n",
        "hidden3 = dense(hidden2, n_hidden3)\n",
        "outputs = dense(hidden3, n_outputs, activation=None)\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhm_cP7opNl",
        "colab_type": "code",
        "outputId": "90c19c76-dfcd-4394-b405-90686e1e5fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Train the model.\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format((100 * i) // n_batches), end=\"\")\n",
        "      sys.stdout.flush()\n",
        "      X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    loss_train = loss.eval(feed_dict={X: X_batch})\n",
        "    print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
        "    saver.save(sess, './my_model_all_layers.ckpt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.01586265\n",
            "1 Train MSE: 0.014260433\n",
            "2 Train MSE: 0.01338274\n",
            "3 Train MSE: 0.012577222\n",
            "4 Train MSE: 0.012467951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fb-Hn6tGGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a plotting function.\n",
        "\n",
        "def show_reconstructed_digits(X, outputs, model_path=None, n_test_digits=2):\n",
        "  with tf.Session() as sess:\n",
        "    if model_path:\n",
        "      saver.restore(sess, model_path)\n",
        "    X_test = mnist.test.images[:n_test_digits]\n",
        "    outputs_val = outputs.eval(feed_dict={X: X_test})\n",
        "  for digit_idx in range(n_test_digits):\n",
        "    plt.subplot(n_test_digits, 2, (digit_idx * 2) + 1)\n",
        "    plot_image(X_test[digit_idx])\n",
        "    plt.subplot(n_test_digits, 2, (digit_idx * 2) + 2)\n",
        "    plot_image(outputs_val[digit_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lm4IG21tzA_",
        "colab_type": "code",
        "outputId": "83b4e503-2c87-44e4-aa1a-388e629d42c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs, './my_model_all_layers.ckpt')\n",
        "save_fig('reconstruction_plot')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure reconstruction_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPKF-a2vNaL",
        "colab_type": "text"
      },
      "source": [
        "### Tying Weights\n",
        "\n",
        "When you are using a near-symmetric autoencoder (like the one above) then you can _tie the weights_ of the decoder layers to th weights of the encoder layers. Specifically, if the autoencoder has $N$ layers and $\\mathbf{W}_L$ is the weights tensor of the $L$<sup>th</sup> layer, then the decoder layer weights can be defined as\n",
        "\n",
        "$$ \\mathbf{W}_{N-L+1} = \\mathbf{W}^{\\;\\,T}_L $$\n",
        "\n",
        "Below is a TensorFlow implementation of a stacked autoencoder which ties weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAL4rZnpxeZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the model graph.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "l2_reg = 0.00005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "weights1_init = he_init([n_inputs, n_hidden1])\n",
        "weights2_init = he_init([n_hidden1, n_hidden2])\n",
        "\n",
        "weights1 = tf.Variable(weights1_init, dtype=tf.float32)\n",
        "weights2 = tf.Variable(weights2_init, dtype=tf.float32)\n",
        "weights3 = tf.transpose(weights2)\n",
        "weights4 = tf.transpose(weights1)\n",
        "\n",
        "bias = lambda n: tf.Variable(tf.zeros(n))\n",
        "bias1 = bias(n_hidden1)\n",
        "bias2 = bias(n_hidden2)\n",
        "bias3 = bias(n_hidden3)\n",
        "bias4 = bias(n_outputs)\n",
        "\n",
        "hidden = lambda X, W, b: tf.nn.elu(tf.matmul(X, W) + b)\n",
        "hidden1 = hidden(X, weights1, bias1)\n",
        "hidden2 = hidden(hidden1, weights2, bias2)\n",
        "hidden3 = hidden(hidden2, weights3, bias3)\n",
        "outputs = tf.matmul(hidden3, weights4) + bias4\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
        "loss = reconstruction_loss + regularizer(weights1) + regularizer(weights2)\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCMl8t-v0uUI",
        "colab_type": "code",
        "outputId": "8794ef06-fd8b-488c-c079-2576edbe330d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Train the model.\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format((100 * i) // n_batches), end=\"\")\n",
        "      sys.stdout.flush()\n",
        "      X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "    saver.save(sess, './my_model_all_layers.ckpt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.0059264963\n",
            "1 Train MSE: 0.0042326236\n",
            "2 Train MSE: 0.004368516\n",
            "3 Train MSE: 0.004215196\n",
            "4 Train MSE: 0.004000963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPKL-lwC1s--",
        "colab_type": "code",
        "outputId": "9fe368cf-8ae4-4759-9b31-c2a45bd2c061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs, './my_model_all_layers.ckpt')\n",
        "save_fig('tying_weight_reconstruction_plot')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure tying_weight_reconstruction_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCRQAnEigAOBEAgUAJxIoADiRQAHA6X9ioiGZz47MtAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgxLRw3KJ5Cy",
        "colab_type": "text"
      },
      "source": [
        "### Train One Autoencoder at a Time in Multiple Graphs\n",
        "\n",
        "You can train a stacked autoencoder in parts:\n",
        "\n",
        "1. First you train the model to reproduce the input layer only using one hidden layer.\n",
        "\n",
        "2. You train an autoencoder which tries to reproduce the output of the first hidden layer (which trains the second and third hidden layer).\n",
        "\n",
        "You can then combine the two results for a fully-functional autoencoder. Below is an implementation of training a stacked autoencoder this way using multiple TensorFlow graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQH99g7CLYrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a function for training an autoencoder in the first 2 steps.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def train_autoencoder(X_train, n_units, n_epochs, batch_size,\n",
        "                      learning_rate=0.001, l2_reg=0.00005, seed=42,\n",
        "                      hidden_activation=tf.nn.elu,\n",
        "                      output_activation=tf.nn.elu):\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    tf.set_random_seed(seed)\n",
        "\n",
        "    n_inputs = X_train.shape[1]\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "    regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "    dense = partial(tf.layers.dense, kernel_initializer=he_init,\n",
        "                    kernel_regularizer=regularizer)\n",
        "    \n",
        "    hidden = dense(X, n_units, activation=hidden_activation, name='hidden')\n",
        "    outputs = dense(hidden, n_inputs, activation=output_activation,\n",
        "                    name='outputs')\n",
        "\n",
        "    reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
        "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "    loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
        "\n",
        "    opt = tf.train.AdamOptimizer(learning_rate)\n",
        "    training_op = opt.minimize(loss)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session(graph=graph) as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = len(X_train) // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        indices = rnd.permutation(len(X_train))[:batch_size]\n",
        "        X_batch = X_train[indices]\n",
        "        sess.run(training_op, feed_dict={X: X_batch})\n",
        "      loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "    params = {\n",
        "      var.name: var.eval()\n",
        "      for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "    }\n",
        "    hidden_val = hidden.eval(feed_dict={X: X_train})\n",
        "  return hidden_val, params['hidden/kernel:0'], params['hidden/bias:0'], \\\n",
        "      params['outputs/kernel:0'], params['outputs/bias:0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyzWX_pR8b1",
        "colab_type": "code",
        "outputId": "f4ee3899-1185-47bb-8dcf-152d45fe3d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# First step of training.\n",
        "\n",
        "hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images,\n",
        "                                                  n_units=256, n_epochs=5,\n",
        "                                                  batch_size=150,\n",
        "                                                  output_activation=None)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.011589399\n",
            "1 Train MSE: 0.0058716172\n",
            "2 Train MSE: 0.0050500864\n",
            "3 Train MSE: 0.004723415\n",
            "4 Train MSE: 0.0044162828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxAu22hgTy5m",
        "colab_type": "code",
        "outputId": "b1d88df5-c9b5-437f-80af-921d6eed2e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Second step of training.\n",
        "\n",
        "_, W2, b2, W3, b3 = train_autoencoder(hidden_output, n_units=128, n_epochs=5,\n",
        "                                      batch_size=150)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.03673815\n",
            "1 Train MSE: 0.013828675\n",
            "2 Train MSE: 0.006784401\n",
            "3 Train MSE: 0.0043381997\n",
            "4 Train MSE: 0.0035973343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16e73kYuUFQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Putting the results together.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
        "outputs = tf.matmul(hidden3, W4) + b4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctjtV9WjXHYZ",
        "colab_type": "code",
        "outputId": "43afb986-97f6-490b-d340-454c3334baee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAD/CAYAAACDzAGWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkVsK0w-XdSq",
        "colab_type": "text"
      },
      "source": [
        "### Training One Autoencoder at a Time in a Single Graph\n",
        "\n",
        "Below is another implementation of the same technique, but this time using just a single TensorFlow graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpmoICWZZyLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the graph.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.01\n",
        "l2_reg = 0.0005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "init_weights = lambda n1, n2, name: \\\n",
        "    tf.Variable(he_init([n1, n2]), dtype=tf.float32, name=name)\n",
        "W1 = init_weights(n_inputs, n_hidden1, 'weights1')\n",
        "W2 = init_weights(n_hidden1, n_hidden2, 'weights2')\n",
        "W3 = init_weights(n_hidden2, n_hidden3, 'weights3')\n",
        "W4 = init_weights(n_hidden3, n_outputs, 'weights4')\n",
        "\n",
        "init_bias = lambda n, name: \\\n",
        "    tf.Variable(tf.zeros(n), dtype=tf.float32, name=name)\n",
        "b1 = init_bias(n_hidden1, name='bias1')\n",
        "b2 = init_bias(n_hidden2, name='bias2')\n",
        "b3 = init_bias(n_hidden3, name='bias3')\n",
        "b4 = init_bias(n_outputs, name='bias4')\n",
        "\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
        "outputs = tf.matmul(hidden3, W4) + b4\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0M7I5yjyBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the training objective for the 1st phase of training.\n",
        "\n",
        "with tf.name_scope('phase1'):\n",
        "  phase1_outputs = tf.matmul(hidden1, W4) + b4\n",
        "  phase1_reconstruction_loss = tf.reduce_mean(tf.square(X - phase1_outputs))\n",
        "  phase1_reg_loss = regularizer(W1) + regularizer(W4)\n",
        "  phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n",
        "  phase1_training_op = optimizer.minimize(phase1_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDPd947PluVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the training objective for the 2nd phase of training.\n",
        "\n",
        "with tf.name_scope('phase2'):\n",
        "  phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden1 - hidden3))\n",
        "  phase2_reg_loss = regularizer(W2) + regularizer(W3)\n",
        "  phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
        "  train_vars = [W2, b2, W3, b3]\n",
        "  phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd_E6Mdxm04Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BspLbkCm-lV",
        "colab_type": "code",
        "outputId": "514f3ba3-35c4-42a8-9a5d-fbb2b71bedf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Training the model.\n",
        "\n",
        "training_ops = [phase1_training_op, phase2_training_op]\n",
        "reconstruction_losses = \\\n",
        "    [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for phase in range(2):\n",
        "    print('Training phase {}'.format(phase + 1))\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = mnist.train.num_examples // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "        sess.run(training_ops[phase], feed_dict={X: X_batch})\n",
        "      loss_train = reconstruction_losses[phase].eval(feed_dict={X: X_batch})\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "      saver.save(sess, './my_model_one_at_a_time.ckpt')\n",
        "  loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
        "  print('Test MSE:', loss_test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training phase 1\n",
            "0 Train MSE: 0.019412301\n",
            "1 Train MSE: 0.018741762\n",
            "2 Train MSE: 0.019461513\n",
            "3 Train MSE: 0.019211361\n",
            "4 Train MSE: 0.018823273\n",
            "Training phase 2\n",
            "0 Train MSE: 0.003732425\n",
            "1 Train MSE: 0.0037449645\n",
            "2 Train MSE: 0.0038264578\n",
            "3 Train MSE: 0.0040227063\n",
            "4 Train MSE: 0.0037791245\n",
            "Test MSE: 0.022631602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n9zsntvuYWY",
        "colab_type": "text"
      },
      "source": [
        "### Caching the Frozen Layer Outputs\n",
        "\n",
        "One way to speed up training is to cache the outputs of the previous phase of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoB0iEtlu1CZ",
        "colab_type": "code",
        "outputId": "89f46667-25a9-4fce-b964-efe81a6def1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "training_ops = [phase1_training_op, phase2_training_op]\n",
        "reconstruction_losses = \\\n",
        "    [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for phase in range(2):\n",
        "    print('Training phase {}'.format(phase + 1))\n",
        "    if phase == 1:\n",
        "      hidden1_cache = hidden1.eval(feed_dict={X: mnist.train.images})\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = mnist.train.num_examples // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        if phase == 1:\n",
        "          indices = rnd.permutation(mnist.train.num_examples)\n",
        "          hidden1_batch = hidden1_cache[indices[:batch_size]]\n",
        "          feed_dict = {hidden1: hidden1_batch}\n",
        "        else:\n",
        "          X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "          feed_dict = {X: X_batch}\n",
        "        sess.run(training_ops[phase], feed_dict=feed_dict)\n",
        "      loss_train = reconstruction_losses[phase].eval(feed_dict=feed_dict)\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "      saver.save(sess, './my_model_cache_frozen.ckpt')\n",
        "  loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
        "  print('Test MSE:', loss_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training phase 1\n",
            "0 Train MSE: 0.018964991\n",
            "1 Train MSE: 0.019229751\n",
            "2 Train MSE: 0.019358424\n",
            "3 Train MSE: 0.018999027\n",
            "4 Train MSE: 0.019247083\n",
            "Training phase 2\n",
            "0 Train MSE: 0.0036740399\n",
            "1 Train MSE: 0.0036927874\n",
            "2 Train MSE: 0.0037944878\n",
            "3 Train MSE: 0.0039010239\n",
            "4 Train MSE: 0.0038886953\n",
            "Test MSE: 0.02300041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4emn0YNvZbd",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the Reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ1hpcE4vltu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f2430058-5a6a-4865-c235-d962e3df4155"
      },
      "source": [
        "n_test_digits = 2\n",
        "X_test = mnist.test.images[:n_test_digits]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, './my_model_one_at_a_time.ckpt')\n",
        "    outputs_val = outputs.eval(feed_dict={X: X_test})\n",
        "\n",
        "def plot_image(image, shape=[28, 28]):\n",
        "    plt.imshow(image.reshape(shape), cmap='Greys', interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "\n",
        "for digit_index in range(n_test_digits):\n",
        "    plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
        "    plot_image(X_test[digit_index])\n",
        "    plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
        "    plot_image(outputs_val[digit_index])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAD/CAYAAACDzAGWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPQCu/A8dthoX4OUAHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Ww6-QVwAA3",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the Extracted Features\n",
        "\n",
        "Below is code which plots the feature weights that the first hidden layer learned during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9TA3o-wHdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ffdeb339-bd26-401d-d16e-c6809c354d74"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, './my_model_one_at_a_time.ckpt')\n",
        "  weights1_val = W1.eval()\n",
        "\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i + 1)\n",
        "  plot_image(weights1_val.T[i])\n",
        "\n",
        "save_fig('extracted_features_plot')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784,)\n",
            "Saving figure extracted_features_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAABXCAYAAAC+w7qGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHvM2kYOxr_V",
        "colab_type": "text"
      },
      "source": [
        "## Unsupervised Pretraining\n",
        "\n",
        "In the code below, we create a neural network for MNIST classification. We first train it alone and see how it performs. Next, we train it again using the features that the unsupervised autoencoder learned and see how the performance compares to when we just did the supervised training alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z5fAH1rxrIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the graph for both training techniques.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_outputs = 10\n",
        "\n",
        "learning_rate = 0.01\n",
        "l2_reg = 0.00005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "y = tf.placeholder(tf.int32, shape=(None))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "init_weights = lambda n1, n2, name: \\\n",
        "    tf.Variable(he_init([n1, n2]), dtype=tf.float32, name=name)\n",
        "W1 = init_weights(n_inputs, n_hidden1, 'weights1')\n",
        "W2 = init_weights(n_hidden1, n_hidden2, 'weights2')\n",
        "W3 = init_weights(n_hidden2, n_outputs, 'weights3')\n",
        "\n",
        "# Don't need to redefine init_bias()\n",
        "b1 = init_bias(n_hidden1, name='bias1')\n",
        "b2 = init_bias(n_hidden2, name='bias2')\n",
        "b3 = init_bias(n_outputs, name='bias3')\n",
        "\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "logits = tf.matmul(hidden2, W3) + b3\n",
        "\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                          logits=logits)\n",
        "reg_loss = regularizer(W1) + regularizer(W2) + regularizer(W3)\n",
        "loss = xentropy + reg_loss\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "pretrain_training_op = opt.minimize(loss, var_list=[W3, b3])\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "pretrain_saver = tf.train.Saver([W1, W2, b1, b2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPqlwp11YEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "de81cbd2-e97e-4fcd-efa6-e4fa95d1d1f3"
      },
      "source": [
        "# Regular training without pretraining.\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "n_labeled_instances = 20000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = n_labeled_instances // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train accuracy:', acc_val, end=' ')\n",
        "    saver.save(sess, './my_model_supervised.ckpt')\n",
        "    acc_val = accuracy.eval(feed_dict={\n",
        "        X: mnist.test.images,\n",
        "        y: mnist.test.labels,\n",
        "    })\n",
        "    print('Test accuracy:', acc_val)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.96 Test accuracy: 0.9324\n",
            "1 Train accuracy: 0.98 Test accuracy: 0.9458\n",
            "2 Train accuracy: 0.97333336 Test accuracy: 0.938\n",
            "3 Train accuracy: 1.0 Test accuracy: 0.9477\n",
            "4 Train accuracy: 0.97333336 Test accuracy: 0.9596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vZigpKb3DTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "4793a332-347d-46ab-ee49-bef26c4847c8"
      },
      "source": [
        "# Now using the layers that were pre-trained. Although it speeds up training,\n",
        "# the model actually performs slightly worse.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  pretrain_saver.restore(sess, './my_model_cache_frozen.ckpt')\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = n_labeled_instances // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(pretrain_training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train accuracy:', acc_val, end=' ')\n",
        "    saver.save(sess, './my_model_supervised.ckpt')\n",
        "    acc_val = accuracy.eval(feed_dict={\n",
        "        X: mnist.test.images,\n",
        "        y: mnist.test.labels,\n",
        "    })\n",
        "    print('Test accuracy:', acc_val)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.9066667 Test accuracy: 0.8827\n",
            "1 Train accuracy: 0.87333333 Test accuracy: 0.8918\n",
            "2 Train accuracy: 0.9 Test accuracy: 0.8939\n",
            "3 Train accuracy: 0.93333334 Test accuracy: 0.8976\n",
            "4 Train accuracy: 0.9266667 Test accuracy: 0.8972\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}