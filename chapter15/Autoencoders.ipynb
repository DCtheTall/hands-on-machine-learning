{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2Yqnh1gXS8",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 15: Autoencoders\n",
        "\n",
        "Autoencoders are an unsupervised neural network architecture who are tasked with reproducing their input. They do so by learning how to encode their inputs using hidden layers that are _smaller_ than the input layer. This forces the model to learn an efficient representation of the data, called _codings_.\n",
        "\n",
        "Below is some setup code which the author uses for the code throughout the chapter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLsyTnsMgU2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Plot styling.\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Code for saving figures.\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"autoencoders\"\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, 'images', '{}.png'.format(fig_id))\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl0abSFRt-yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image, shape=[28, 28]):\n",
        "    plt.imshow(image.reshape(shape), cmap='Greys', interpolation='nearest')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olJpqlG4KYMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtkKk8HxGzL5",
        "colab_type": "text"
      },
      "source": [
        "## Performing PCA with an Undercomplete Linear Autoencoder\n",
        "\n",
        "An autoencoder with only linear activation functions that uses MSE as the loss function can be shown to be equivalent to PCA (Chapter 8)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQXLRrN3Gymx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a 3D dataset.\n",
        "\n",
        "import numpy.random as rnd\n",
        "\n",
        "rnd.seed(42)\n",
        "m = 200\n",
        "w1, w2 = 0.1, 0.3\n",
        "noise = 0.1\n",
        "\n",
        "angles = rnd.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "data = np.empty((m, 3))\n",
        "data[:, 0] = np.cos(angles) + (np.sin(angles) / 2) + (noise * rnd.randn(m) / 2)\n",
        "data[:, 1] = (np.sin(angles) * 0.7) + (noise * rnd.randn(m) / 2)\n",
        "data[:, 2] = (data[:, 0] * w1) + (data[:, 1] * w2) + (noise * rnd.randn(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4N4ceT_H1-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data with StandardScaler.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(data[:100])\n",
        "X_test = scaler.transform(data[100:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKrj7NTVIl1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model graph.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 3\n",
        "n_hidden = 2\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "hidden = tf.layers.dense(X, n_hidden)\n",
        "outputs = tf.layers.dense(hidden, n_outputs)\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(reconstruction_loss)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWZb2YAsJoK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the autoencoder.\n",
        "\n",
        "n_iterations = 100\n",
        "codings = hidden\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for i in range(n_iterations):\n",
        "    training_op.run(feed_dict={X: X_train})\n",
        "  codings_val = codings.eval(feed_dict={X: X_test})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUAIdt0oKDO0",
        "colab_type": "code",
        "outputId": "a973cb7e-65d8-4976-d5f7-1f378b2982d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Plotting the figure.\n",
        "\n",
        "fig = plt.figure(figsize=(4,3))\n",
        "plt.plot(codings_val[:,0], codings_val[:, 1], 'b.')\n",
        "plt.xlabel('$z_1$', fontsize=18)\n",
        "plt.ylabel('$z_2$', fontsize=18, rotation=0)\n",
        "save_fig('linear_autoencoder_pca_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure linear_autoencoder_pca_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAADQCAYAAADcQn7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc0YcMeLd8PE",
        "colab_type": "text"
      },
      "source": [
        "## Stacked Autoencoders\n",
        "\n",
        "Autoencoders with multiple hidden layers are called _stacked autoencoders_ (or _deep autoencoders_). You must be wary that if the autoencoder is too deep, it may just learn how to reproduce the training set, leading to overfitting. Below is a TensorFlow implementation of a stacked autoencoder with 3 hidden layers used for generating handwritten digits using the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGCKRSUzfNG9",
        "colab_type": "code",
        "outputId": "f43e2a62-a5c7-40c6-bf40-082bef2ed0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Downloading the data.\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuAyScFRf3Cd",
        "colab_type": "text"
      },
      "source": [
        "### Train all layers at once\n",
        "\n",
        "The example below trains all of the hidden layers of the stacked autoencoder at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0E4zltAf2iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model graph.\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "l2_reg = 0.0001\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "dense = partial(tf.layers.dense, activation=tf.nn.relu,\n",
        "                kernel_initializer=he_init, kernel_regularizer=regularizer)\n",
        "\n",
        "hidden1 = dense(X, n_hidden1)\n",
        "hidden2 = dense(hidden1, n_hidden2)\n",
        "hidden3 = dense(hidden2, n_hidden3)\n",
        "outputs = dense(hidden3, n_outputs, activation=None)\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhm_cP7opNl",
        "colab_type": "code",
        "outputId": "359ae3bd-8d5b-4043-ea92-d81421f2e5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Train the model.\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format((100 * i) // n_batches), end=\"\")\n",
        "      sys.stdout.flush()\n",
        "      X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    loss_train = loss.eval(feed_dict={X: X_batch})\n",
        "    print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
        "    saver.save(sess, './my_model_all_layers.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.015861776\n",
            "1 Train MSE: 0.014257669\n",
            "2 Train MSE: 0.013384858\n",
            "3 Train MSE: 0.012632973\n",
            "4 Train MSE: 0.012566684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fb-Hn6tGGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a plotting function.\n",
        "\n",
        "def show_reconstructed_digits(X, outputs, model_path=None, n_test_digits=2):\n",
        "  with tf.Session() as sess:\n",
        "    if model_path:\n",
        "      saver.restore(sess, model_path)\n",
        "    X_test = mnist.test.images[:n_test_digits]\n",
        "    outputs_val = outputs.eval(feed_dict={X: X_test})\n",
        "  for digit_idx in range(n_test_digits):\n",
        "    plt.subplot(n_test_digits, 2, (digit_idx * 2) + 1)\n",
        "    plot_image(X_test[digit_idx])\n",
        "    plt.subplot(n_test_digits, 2, (digit_idx * 2) + 2)\n",
        "    plot_image(outputs_val[digit_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lm4IG21tzA_",
        "colab_type": "code",
        "outputId": "9afb318d-810a-4027-b383-506d3f8f456a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs, './my_model_all_layers.ckpt')\n",
        "save_fig('reconstruction_plot')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure reconstruction_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPKF-a2vNaL",
        "colab_type": "text"
      },
      "source": [
        "### Tying Weights\n",
        "\n",
        "When you are using a near-symmetric autoencoder (like the one above) then you can _tie the weights_ of the decoder layers to th weights of the encoder layers. Specifically, if the autoencoder has $N$ layers and $\\mathbf{W}_L$ is the weights tensor of the $L$<sup>th</sup> layer, then the decoder layer weights can be defined as\n",
        "\n",
        "$$ \\mathbf{W}_{N-L+1} = \\mathbf{W}^{\\;\\,T}_L $$\n",
        "\n",
        "Below is a TensorFlow implementation of a stacked autoencoder which ties weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAL4rZnpxeZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the model graph.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "l2_reg = 0.00005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "weights1_init = he_init([n_inputs, n_hidden1])\n",
        "weights2_init = he_init([n_hidden1, n_hidden2])\n",
        "\n",
        "weights1 = tf.Variable(weights1_init, dtype=tf.float32)\n",
        "weights2 = tf.Variable(weights2_init, dtype=tf.float32)\n",
        "weights3 = tf.transpose(weights2)\n",
        "weights4 = tf.transpose(weights1)\n",
        "\n",
        "bias = lambda n: tf.Variable(tf.zeros(n))\n",
        "bias1 = bias(n_hidden1)\n",
        "bias2 = bias(n_hidden2)\n",
        "bias3 = bias(n_hidden3)\n",
        "bias4 = bias(n_outputs)\n",
        "\n",
        "hidden = lambda X, W, b: tf.nn.elu(tf.matmul(X, W) + b)\n",
        "hidden1 = hidden(X, weights1, bias1)\n",
        "hidden2 = hidden(hidden1, weights2, bias2)\n",
        "hidden3 = hidden(hidden2, weights3, bias3)\n",
        "outputs = tf.matmul(hidden3, weights4) + bias4\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
        "loss = reconstruction_loss + regularizer(weights1) + regularizer(weights2)\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCMl8t-v0uUI",
        "colab_type": "code",
        "outputId": "2babbdc0-75f9-4827-d330-b957a17999e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Train the model.\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format((100 * i) // n_batches), end=\"\")\n",
        "      sys.stdout.flush()\n",
        "      X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "    saver.save(sess, './my_model_all_layers.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.0059264963\n",
            "1 Train MSE: 0.0042326236\n",
            "2 Train MSE: 0.004368516\n",
            "3 Train MSE: 0.004215196\n",
            "4 Train MSE: 0.004000963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPKL-lwC1s--",
        "colab_type": "code",
        "outputId": "9bb05bec-eb8d-42b7-8d42-951992bc80fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs, './my_model_all_layers.ckpt')\n",
        "save_fig('tying_weight_reconstruction_plot')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure tying_weight_reconstruction_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFndJREFUeJzt3WmoVdUbx/FlOd6reVNzKseiciIs\nNKcXNhlZKBZBA1JkgxQFBRUFQQXRm6B8E5VFlkUEhVaERWmilWWTDVYO2WA5ZDlk9zql/t/U/q/n\np2dt93POved67/fzaj2sfc7e5+h52Pu5a2hz8ODBAAAo7phqXwAAHK1IoADgRAIFACcSKAA4kUAB\nwIkECgBOJFAAcCKBAoATCRQAnNpW6bxMf2r+2lT7AlqDhoaGo/630KbN//+rtMSZjTU1NSV/C9yB\nAoATCRQAnKr1CA+gTPGjcwjVe3wuct4i16zHlqOxvhvuQAHAiQQKAE48wgNHqSKPpXpskcdjPbbI\nY7j2peJKnqec9yqCO1AAcCKBAoATCRQAnKiBAq3AMcfYe6UDBw6YOK4Jan3w2GOPNbHWE+P31r7U\nefKuMa+/SE1UVWr2FHegAOBEAgUAJxIoADhRAwWaqbyxi6mxnHnjIFO1Sq1barx///6S16X10nbt\n2pU8Vt/7n3/+SR7btq1NV/G58q45r67rxR0oADiRQAHAiQQKAE7UQIGjlNb1UuMxlfZrfTFWpCaq\nfXv27Cl5jSHYumdezXffvn0lz5v6Lg6HufAAUGUkUABw4hEeaKaKPmamHqV37dpl4r1795r4uOOO\ny9rt27c3fTrkp2PHjiWvQR/Z9Tr0vTp06JC19RFej9X3iunjvR6bGrZVzlJ33IECgBMJFACcSKAA\n4NSiaqAfffSRiWfNmmXiE0880cSdOnXK2tdcc43p69atWzIGGkORZda07tfQ0JC1f/rpJ9O3bNky\nE2/ZssXEgwYNyto9evQwff369TPxwIEDTVxbW1vyGnXap8ZxLTY1RTSEQ4cmxbXYolMzK7XjJ3eg\nAOBEAgUAJxIoADi1qdSUpoIa5aSnnXaaidesWeN+r65du5p4zJgx7vcqh9ab7rnnnqzdv3//xjx1\nZYpESGpoaDC/hVRtTsc26ljOzZs3Z+2lS5eavoULF5p4w4YNJo7rnFpb1fPU1NSYOF6yLrVcXQh2\n3Kf2x2NRQzh0emldXZ2JJ02alLWHDh2afG1qDGneViE1NTUl/1G4AwUAJxIoADiRQAHAqUWNA50/\nf76JV6xYYeJhw4aZeOXKlVn7448/Nn2vvfaaid9++20Tx+Pmfvzxx0LXGddn+vTpY/rWr1+ffG1c\nE7377rsLnRfNX1wDTW0fHMKhdb14XKT+PUDrmlrHjMdRrlq1yvStW7fOxFu3bjVx/P9Zt+XYvn27\nibWe2rNnz6ytn/fTTz81cTxuOwT7e86rgep543PlzZtP4Q4UAJxIoADg1KKGMVXS7t27TaxT4+JH\neH3EyRMvF6aP8PH7hnDolLt58+Zl7alTpxY6b0EMY2oCqWFMOj1RH0t16mO8lFzesnKdO3c2cfz/\n/e+//y7Zd7hYd96M6f9f/UxdunTJ2n/99Zfpe+ihh0y8ceNGEz/yyCNZe+zYsaZPl+TTEkaRR/hO\nnToxjAkAKo0ECgBOJFAAcGpRw5gqSbctOP3000seO2TIEPd5dPjUH3/8YeKzzz7bxPH0NRz9ikzd\nVFoTjd9L+7ROqUOi4tfqNObUbpj63vo3FV1CUqdyxtehv4U///zTxKNHjzZxPJVZP49eYxFs6QEA\nTYAECgBOJFAAcKIGWgX19fVZe9q0aaZP616PPfaYiXU6G1ourcXpNEkV9+tr87bWiGug2pc3TjI+\nPjXeMoRDa5U//PBD1p49e7bp02mgkydPNnE8hlq/m7zzVgp3oADgRAIFACcSKAA4UQOtgjlz5mTt\nTZs2mb7u3bubeMCAAU1xSWiG8rbHKFIj1WNT40/1WB1Dmtp+OG/+frz1cgh2q5ElS5aYvgkTJph4\n1KhRJo7Hauv8/CL0u2AcKAA0ARIoADjxCN8E4qEaIYRwxx13lDx22bJlJu7du3ejXBOah3KWk9Sh\nOXGsj/v6GJ5aGi+vdKCvjUsHebtwrl692sSLFi3K2r169TJ906dPN3G3bt1MnCodlIMV6QGgCZBA\nAcCJBAoATtRAm8Abb7xh4ni62+WXX276Bg8e3CTXhKOf1irjGmhquboQDq1VxjXQcqZBaq1Vd8Nc\nvny5ib/66qusfemll5o+XcpRxe+t16zXUakhXoo7UABwIoECgBMJFACcqIE2Al3SK96KOAQ7Nu7h\nhx82fZUcz4ajT1x/yxuPqYqMi0wtUZf32tRyd7oVjk5V/uabb0zcs2fPrD1lyhTTp++Vt6zekV5j\n3muZygkATYAECgBOJFAAcKIG2gieeeYZEy9dutTEV111VdZm3Cdi5cyNT23LkSdV99Sl4vTY9u3b\nZ+1du3aZvgULFpj4k08+MfH555+ftXXrcK1b6ljO1DXn1YsrhTtQAHAigQKAE4/wFbBixQoT33rr\nrSauq6sz8YMPPtjo14SjQznDaYpMQcxbki5+bd6jsi5RF/v8889NPHfuXBPrEL/LLrssa9fU1Ji+\nvF1I4+sqWrJIDRcrgjtQAHAigQKAEwkUAJyogTrFwzWuvPJK06f1mKuvvtrEDF3Cf1J1zLwl6FLv\npa/VOqb2x/9n87YD0fdat25d1p49e7bp0+1sbrnlFhOfeuqpWVuXzdPfUTxcKgT7ectZkq4c3IEC\ngBMJFACcSKAA4EQN9AhpXejiiy/O2qtWrTJ9Q4YMMfEDDzzQeBeGFiU1JlH7UnVNrQGmtv8IIYQ9\ne/aUPK+OGd25c6eJ58yZk7Xfeecd0zd58mQTX3HFFSaOx5Tqb0yXs9PPUGTsZ9734cUdKAA4kUAB\nwIkECgBO1ECP0NatW028ePHiksfq/N9u3bo1xiWhBSpnjnbqeK0Xak0wNb9dX6vbcsS/hWHDhpm+\nGTNmmLh3794mTo1tzRsHm6r5FsFceACoAhIoADjxCF/Cjh07TDxmzJiSx77wwgsmHjlyZKNcE1q+\n1HTMIkNx9FgdtqRLxcX9+r66s+Ybb7xh4m3btmVtnaqpvwUdEpVasq7IqvJ6zXmP5fp9FHmteZ8j\nPhIAYJBAAcCJBAoATtRAS3j22WdNHC/ZpSZMmGDiplpKCy1bOcOYtH6Yt0RdbO/evSb+6KOPTDx/\n/nwTx8P09G8FOjxKa57xFh86NVXrlBqXUyOtFO5AAcCJBAoATiRQAHCiBvqvNWvWmPj++++vzoWg\nVUtN5cwbB5qq82n9MDVN8ueffzZ9r7/+uolXr15t4nhr4traWtOn9dTU+FOty+rnSU3lzKtxpr47\npnICQBWQQAHAiQQKAE7UQP+1dOlSE//111/J4+NtOzp16tQo14TWp0g9Lm+ufCw19zuEELZv3561\nly9fbvq05qlL0g0dOjRraw1Uz6t1ziJL0hUZX533PbKlBwBUGQkUAJx4hD9C48aNM3G8+yCP8KiG\nvBXbU326ynzcP2jQINN3ww03mPj444838RlnnJG19RE+NfQoBPsordfUWNMvVTk7dnIHCgBOJFAA\ncCKBAoBTm6aqM4iqnBSFsCZfE2hoaGgWv4W4/qg5IW8aaKpPX5uanlp0W45KyauB1tTUlPzA3IEC\ngBMJFACcSKAA4FStGigAHPW4AwUAJxIoADiRQAHAiQQKAE4kUABwIoECgBMJFACcSKAA4EQCBQAn\nEigAOJFAAcCJBAoATiRQAHAigQKAEwkUAJxIoADgRAIFACcSKAA4kUABwIkECgBOJFAAcCKBAoAT\nCRQAnEigAOBEAgUAJxIoADiRQAHAiQQKAE4kUABwIoECgBMJFACcSKAA4EQCBQCntlU678EqnRdH\nrk21L6A1qK+v57fQzNXW1pb8LXAHCgBOJFAAcCKBAoBTtWqgAJqpgwfTZdk2bWxJMHW8HlvEMcfY\n+zs9T951NgXuQAHAiQQKAE48wgMIBw4cOGw7hPxH5X379h22HUIIxx57rIlrampM3Lbt/1OQPu5r\nvH///pL9es2qnFJCCnegAOBEAgUAJxIoADhRA/3Xiy++aOL6+noTf/bZZyZ+6qmnSr7XfffdZ+Jz\nzz3XxBMnTnRcIeCnNcC9e/eaeNu2bVl748aNpu+7774z8a+//mri9evXZ+2OHTuavgEDBph4zJgx\nJh48eHDW7tq1q+nLG8YUKzK0qpK4AwUAJxIoADiRQAHAqU2VpkNVfw5WCOHmm2/O2k8++WSjnWfo\n0KEmfv/997O21n2aEZazawKVXM4uNdZx9+7dJt60aZOJlyxZkrUXLVpk+rT+rzXSf/75J2t36dLF\n9PXv39/E55xzjomnTZuWtUeMGGH6OnToYGIdYxp/Xh1vmjcuNK6v5uVAlrMDgEZAAgUAJxIoADi1\nqnGgcc0zhGJ1z5EjR5r4sssuy9pr1qwxfc8995yJv/32WxO/8sorWXvGjBlHfA1ATGuecV1P541v\n377dxO+9956Jn3766az99ddfm77hw4ebeMqUKSbu0aNH1t65c6fpe/PNN028ePFiE5966qlZe9iw\nYaZP65ipOqfWMfXYuE4bgv1+8ubgp3AHCgBOJFAAcGrRj/C//PKLiePHFDVq1CgTv/XWWybWZbja\nt2+ftfVxae3atSb+4IMPTPzHH3+UvA6gEvTxd/PmzSbW/5Px9MxLLrnE9N19990m1kft+LewevVq\n06e/hU8//dTE8e+qXbt2pk+ncqr4MV0/r8apqZ5Fpowq7kABwIkECgBOJFAAcGrRNVCtNWptI657\nvvvuu6avc+fOR3yeOXPmmPiTTz5JHj916tQjfm/gP1rHi7fDUDpsR6dy9unTx8Q33nhj1p4+fbrp\n69u3r4l1imV8rg0bNpi+FStWmFjrjXV1dVlb/5agS+5pjTQ13Cg1xCuE9BCoIrgDBQAnEigAOJFA\nAcCpRddAzzzzTBNrTTQev9apUyf3eXR8qdZuAI+8cZCpsY06lVFrnpdffrmJ4601jj/+eNPX0NBg\nYt3u5s8//8zaCxcuNH26bJ7+JuP6aqpOGcKhNdB4eTt9rX43eeNCvbgDBQAnEigAOJFAAcCpRddA\nVSW3z5g7d27W/vLLL5PHTpo0ycQnn3xyxa4DLUtcm8vblkL7U/O7dWuNgQMHlnwvrXlqPVXHa37+\n+edZe968eclrHD9+vIm7d+8ejpSeN/6M+nk11tfGGAcKAFVAAgUAp1b1CF+OL774wsQ33XRT1t6z\nZ4/p0yEjs2bNMrEOxwD+k/fYHtNHz3hKpT7C6rRPfaTdsmVL1tZhTLqUo+7A8Oqrr2btrVu3mr6J\nEyea+KKLLjJxXFbTa9JrTn03+pvSqaypx3TtY0V6AGgCJFAAcCKBAoATNdAjtGzZMhNr3TM2c+ZM\nE8c7DwIpRZZo09pdHGu9UGuC8TTIEEKora3N2jqtWadAv/TSSyZ+5513svaAAQNMn+7gOWTIEBPH\n59Jr1jpuqq6p30Vq2FIIhw7NilEDBYAmQAIFACcSKAA4UQMt4brrrjPxyy+/XPLY22+/3cR33XVX\no1wTWhetxeXFqeXstH6o4i1sdLm6+fPnm3jJkiUmPu6447L2pZdeavp0HGi3bt1MvHPnzqydN5ZT\nP298vC4hqa/VMaXxezGVEwCqgAQKAE4kUABwogb6r7///tvECxYsMLFuC9urV6+sfe+995q+eKsQ\nwCtvjrb2x+ModRyk1gR1fntM1314++23Tbx+/XoTn3feeVl79OjRpk/XhUiNn9ZxoEW2Nda+1BjZ\nEOwYU2qgAFAFJFAAcOIR/l+6S+Hvv/+ePP62227L2jo0A6iEvMdQfaSPH0u15KTTM3WY06+//pq1\ntXz1/vvvm1hXsx87dmzW1l03O3ToYOIdO3aYOB5e1LFjR9Onj/CpoVn6XeQthVfOY3uMO1AAcCKB\nAoATCRQAnFp1DfSzzz7L2osXL04eq1PU7rjjjsa4JCBTzlROHdaj8a5du0z8ww8/ZO34dxHCobXH\nESNGmHjcuHFZu0uXLqYvbyhSPORPh16llpwLwW4fUldXZ/q0BqqogQJAlZFAAcCJBAoATq2qBqp1\nn3vuuSdra61GnXXWWSZmuiaamtbttEYYx3nTPjds2GDieLrm999/b/p69Ohh4gsvvNDEJ510Usnz\n6NYhWpuMY906JN5mJIT0lh/6XeR9fqZyAkCVkUABwIkECgBOraoG+sQTT5h44cKFJY/VLT0Y94lq\n021+U3PjtS/eOiOEEJYuXWriN998M2vr3womTZpkYv17QDzPXper09qkznePa6S6xJ4eq5+/b9++\nWVtrng0NDSbW5fzi98rbTjmFO1AAcCKBAoBTq3qE15XjUx599FETM2wJzY0+esZ0yqQuz7h8+XIT\nb9y4MWtfcMEFpm/69OkmjocthWAf07V0oI/Oqd0ydck9LSXoEKh46ufmzZtN32+//WZiXVavX79+\nWbuc3zZ3oADgRAIFACcSKAA4taoaaBG6S2eRoQ1K6y9xzUiX8ErtWhiCrQvNmjWr0HXE59V6sNbM\n0PxofVH/78T/hvrvqfXSLVu2mHj79u1ZW4cE6RTLH3/80cTxkCGtW55wwgkm1mFN8XY4ek26+6fW\nT3/++eesvXLlStOnQ6ImTpxY8rr0t13kt8AdKAA4kUABwIkECgBO1EBLOPHEEyv2XjNnzjRxPAVt\n06ZNpu/xxx+v2HlT9PNdf/31TXJeHDmtW+Ztzau1y5jWD3XMZfxaneapY0h16ce4bj948GDT179/\nfxPr9MxevXpl7dWrV5u+eMuOEEKor6838bp167K21jG15pnaIrqcv29wBwoATiRQAHAigQKAU6uq\ngV599dUmfvbZZ5vkvLqMXhE6/ze11eu1115r4rFjx5Y8dvz48e5rQuOJa3Na09QaqPbv3r07a2uN\nU7cbHjlypInXrFmTtXXcp27/obXJ+Pgvv/zS9OlY1bjmqdelS9D17NnTxN27dzdxXMeP/64QQgij\nR482ce/evU0c12KpgQJAFZBAAcCpTTk70pWhKidVzz//fNbO25VTxY8qRYce3XnnnVn7lFNOSR47\nZcoUE+tjTSMqPSYGFVNfX1/yt1BkmFII9nFZpyNq6UeXe/vwww+zdry0XQiH7o6pj9pr167N2jrk\nKZ5uGUIIAwYMMPHw4cOzti4rp//XdRm9+DNqyUIf97t27WrieKqnlslUbW1tyS+eO1AAcCKBAoAT\nCRQAnFp1DRRJ1ECbQJEaqA5j0jqnTtdMHav11Pi1el6tEaaW1dO/JeiykHV1dSZO7Y6ZV8eNr1nP\nm9qFMwRbb82rLVMDBYBGQAIFACcSKAA4taqpnMDRRGtzWsdL1Qy1T2uCWk+Mz6Wv3bdvX/K88Wt1\nK43OnTubWOup8XXptE89VuP4+9C6bOrzVRJ3oADgRAIFACcSKAA4UQMFjhJ5dbzUUnh59dO4X1+b\nN1c8rmNqvVTrmnod8TWntt04XJyin4EaKAA0MyRQAHDiER5oIeLH8rxHWH0cjh/Di67QHr933qOy\nlg5Kvc/hjtXyQKV21iwHd6AA4EQCBQAnEigAOFEDBVqgokOA4vpjarm6PFqL1LqmTrFM1USLqNKy\nnNyBAoAXCRQAnEigAOBUrS09AOCoxx0oADiRQAHAiQQKAE4kUABwIoECgBMJFACcSKAA4EQCBQAn\nEigAOJFAAcCJBAoATiRQAHAigQKAEwkUAJxIoADgRAIFACcSKAA4kUABwIkECgBOJFAAcCKBAoAT\nCRQAnEigAOBEAgUAJxIoADiRQAHA6X9ioiGZz47MtAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgxLRw3KJ5Cy",
        "colab_type": "text"
      },
      "source": [
        "### Train One Autoencoder at a Time in Multiple Graphs\n",
        "\n",
        "You can train a stacked autoencoder in parts:\n",
        "\n",
        "1. First you train the model to reproduce the input layer only using one hidden layer.\n",
        "\n",
        "2. You train an autoencoder which tries to reproduce the output of the first hidden layer (which trains the second and third hidden layer).\n",
        "\n",
        "You can then combine the two results for a fully-functional autoencoder. Below is an implementation of training a stacked autoencoder this way using multiple TensorFlow graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQH99g7CLYrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a function for training an autoencoder in the first 2 steps.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def train_autoencoder(X_train, n_units, n_epochs, batch_size,\n",
        "                      learning_rate=0.001, l2_reg=0.00005, seed=42,\n",
        "                      hidden_activation=tf.nn.elu,\n",
        "                      output_activation=tf.nn.elu):\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    tf.set_random_seed(seed)\n",
        "\n",
        "    n_inputs = X_train.shape[1]\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "    regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "    dense = partial(tf.layers.dense, kernel_initializer=he_init,\n",
        "                    kernel_regularizer=regularizer)\n",
        "    \n",
        "    hidden = dense(X, n_units, activation=hidden_activation, name='hidden')\n",
        "    outputs = dense(hidden, n_inputs, activation=output_activation,\n",
        "                    name='outputs')\n",
        "\n",
        "    reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
        "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "    loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
        "\n",
        "    opt = tf.train.AdamOptimizer(learning_rate)\n",
        "    training_op = opt.minimize(loss)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session(graph=graph) as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = len(X_train) // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        indices = rnd.permutation(len(X_train))[:batch_size]\n",
        "        X_batch = X_train[indices]\n",
        "        sess.run(training_op, feed_dict={X: X_batch})\n",
        "      loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "    params = {\n",
        "      var.name: var.eval()\n",
        "      for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "    }\n",
        "    hidden_val = hidden.eval(feed_dict={X: X_train})\n",
        "  return hidden_val, params['hidden/kernel:0'], params['hidden/bias:0'], \\\n",
        "      params['outputs/kernel:0'], params['outputs/bias:0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyzWX_pR8b1",
        "colab_type": "code",
        "outputId": "307c7242-f955-4627-846c-6a846e2dd404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# First step of training.\n",
        "\n",
        "hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images,\n",
        "                                                  n_units=256, n_epochs=5,\n",
        "                                                  batch_size=150,\n",
        "                                                  output_activation=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.011589399\n",
            "1 Train MSE: 0.0058716172\n",
            "2 Train MSE: 0.0050500864\n",
            "3 Train MSE: 0.004723415\n",
            "4 Train MSE: 0.0044162828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxAu22hgTy5m",
        "colab_type": "code",
        "outputId": "21aba720-1f73-47b2-9f72-7008814528c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Second step of training.\n",
        "\n",
        "_, W2, b2, W3, b3 = train_autoencoder(hidden_output, n_units=128, n_epochs=5,\n",
        "                                      batch_size=150)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.036738154\n",
            "1 Train MSE: 0.013828675\n",
            "2 Train MSE: 0.006784402\n",
            "3 Train MSE: 0.0043382\n",
            "4 Train MSE: 0.0035973343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16e73kYuUFQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Putting the results together.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
        "outputs = tf.matmul(hidden3, W4) + b4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctjtV9WjXHYZ",
        "colab_type": "code",
        "outputId": "88b32b32-9c64-458e-bf80-c8e26444ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "show_reconstructed_digits(X, outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAD/CAYAAACDzAGWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkVsK0w-XdSq",
        "colab_type": "text"
      },
      "source": [
        "### Training One Autoencoder at a Time in a Single Graph\n",
        "\n",
        "Below is another implementation of the same technique, but this time using just a single TensorFlow graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpmoICWZZyLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the graph.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.01\n",
        "l2_reg = 0.0005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "init_weights = lambda n1, n2, name: \\\n",
        "    tf.Variable(he_init([n1, n2]), dtype=tf.float32, name=name)\n",
        "W1 = init_weights(n_inputs, n_hidden1, 'weights1')\n",
        "W2 = init_weights(n_hidden1, n_hidden2, 'weights2')\n",
        "W3 = init_weights(n_hidden2, n_hidden3, 'weights3')\n",
        "W4 = init_weights(n_hidden3, n_outputs, 'weights4')\n",
        "\n",
        "init_bias = lambda n, name: \\\n",
        "    tf.Variable(tf.zeros(n), dtype=tf.float32, name=name)\n",
        "b1 = init_bias(n_hidden1, name='bias1')\n",
        "b2 = init_bias(n_hidden2, name='bias2')\n",
        "b3 = init_bias(n_hidden3, name='bias3')\n",
        "b4 = init_bias(n_outputs, name='bias4')\n",
        "\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
        "outputs = tf.matmul(hidden3, W4) + b4\n",
        "\n",
        "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0M7I5yjyBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the training objective for the 1st phase of training.\n",
        "\n",
        "with tf.name_scope('phase1'):\n",
        "  phase1_outputs = tf.matmul(hidden1, W4) + b4\n",
        "  phase1_reconstruction_loss = tf.reduce_mean(tf.square(X - phase1_outputs))\n",
        "  phase1_reg_loss = regularizer(W1) + regularizer(W4)\n",
        "  phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n",
        "  phase1_training_op = optimizer.minimize(phase1_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDPd947PluVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the training objective for the 2nd phase of training.\n",
        "\n",
        "with tf.name_scope('phase2'):\n",
        "  phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden1 - hidden3))\n",
        "  phase2_reg_loss = regularizer(W2) + regularizer(W3)\n",
        "  phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
        "  train_vars = [W2, b2, W3, b3]\n",
        "  phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd_E6Mdxm04Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BspLbkCm-lV",
        "colab_type": "code",
        "outputId": "e24bdb69-0e0e-4904-9d88-486504638f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "# Training the model.\n",
        "\n",
        "training_ops = [phase1_training_op, phase2_training_op]\n",
        "reconstruction_losses = \\\n",
        "    [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for phase in range(2):\n",
        "    print('Training phase {}'.format(phase + 1))\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = mnist.train.num_examples // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "        sess.run(training_ops[phase], feed_dict={X: X_batch})\n",
        "      loss_train = reconstruction_losses[phase].eval(feed_dict={X: X_batch})\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "      saver.save(sess, './my_model_one_at_a_time.ckpt')\n",
        "  loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
        "  print('Test MSE:', loss_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training phase 1\n",
            "0 Train MSE: 0.018336492\n",
            "1 Train MSE: 0.019637663\n",
            "2 Train MSE: 0.019277904\n",
            "3 Train MSE: 0.018733133\n",
            "4 Train MSE: 0.020028505\n",
            "Training phase 2\n",
            "0 Train MSE: 0.0037001013\n",
            "1 Train MSE: 0.0036114932\n",
            "2 Train MSE: 0.0036930295\n",
            "3 Train MSE: 0.0037119866\n",
            "4 Train MSE: 0.004263958\n",
            "Test MSE: 0.022761209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n9zsntvuYWY",
        "colab_type": "text"
      },
      "source": [
        "### Caching the Frozen Layer Outputs\n",
        "\n",
        "One way to speed up training is to cache the outputs of the previous phase of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoB0iEtlu1CZ",
        "colab_type": "code",
        "outputId": "e253c0c7-dd36-42a2-a9eb-125ace7f84c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "training_ops = [phase1_training_op, phase2_training_op]\n",
        "reconstruction_losses = \\\n",
        "    [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
        "n_epochs = 5\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for phase in range(2):\n",
        "    print('Training phase {}'.format(phase + 1))\n",
        "    if phase == 1:\n",
        "      hidden1_cache = hidden1.eval(feed_dict={X: mnist.train.images})\n",
        "    for epoch in range(n_epochs):\n",
        "      n_batches = mnist.train.num_examples // batch_size\n",
        "      for i in range(n_batches):\n",
        "        print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "        sys.stdout.flush()\n",
        "        if phase == 1:\n",
        "          indices = rnd.permutation(mnist.train.num_examples)\n",
        "          hidden1_batch = hidden1_cache[indices[:batch_size]]\n",
        "          feed_dict = {hidden1: hidden1_batch}\n",
        "        else:\n",
        "          X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "          feed_dict = {X: X_batch}\n",
        "        sess.run(training_ops[phase], feed_dict=feed_dict)\n",
        "      loss_train = reconstruction_losses[phase].eval(feed_dict=feed_dict)\n",
        "      print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
        "      saver.save(sess, './my_model_cache_frozen.ckpt')\n",
        "  loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
        "  print('Test MSE:', loss_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training phase 1\n",
            "0 Train MSE: 0.017883915\n",
            "1 Train MSE: 0.018957019\n",
            "2 Train MSE: 0.019209469\n",
            "3 Train MSE: 0.019031227\n",
            "4 Train MSE: 0.019129302\n",
            "Training phase 2\n",
            "0 Train MSE: 0.0036775959\n",
            "1 Train MSE: 0.003967436\n",
            "2 Train MSE: 0.0039204685\n",
            "3 Train MSE: 0.003805287\n",
            "4 Train MSE: 0.0039625303\n",
            "Test MSE: 0.022798782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4emn0YNvZbd",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the Reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ1hpcE4vltu",
        "colab_type": "code",
        "outputId": "01c35a4d-cee4-49ff-a73c-3add52a62883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "n_test_digits = 2\n",
        "X_test = mnist.test.images[:n_test_digits]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, './my_model_one_at_a_time.ckpt')\n",
        "    outputs_val = outputs.eval(feed_dict={X: X_test})\n",
        "\n",
        "def plot_image(image, shape=[28, 28]):\n",
        "    plt.imshow(image.reshape(shape), cmap='Greys', interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "\n",
        "for digit_index in range(n_test_digits):\n",
        "    plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
        "    plot_image(X_test[digit_index])\n",
        "    plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
        "    plot_image(outputs_val[digit_index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAD/CAYAAACDzAGWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nix4AV1j0ALjCogfAFRY9AK78Hwc/IijSPEdcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Ww6-QVwAA3",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the Extracted Features\n",
        "\n",
        "Below is code which plots the feature weights that the first hidden layer learned during training. You can even see some feature maps that resemble actual digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9TA3o-wHdD",
        "colab_type": "code",
        "outputId": "a2b22a00-f581-4fc1-ac58-bc1edb186c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, './my_model_one_at_a_time.ckpt')\n",
        "  weights1_val = W1.eval()\n",
        "\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i + 1)\n",
        "  plot_image(weights1_val.T[i])\n",
        "\n",
        "save_fig('extracted_features_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure extracted_features_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAABXCAYAAAC+w7qGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ziOEyw+SDmO4zjB4oOU4ziOEyz/AbocvQ3LVEBgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHvM2kYOxr_V",
        "colab_type": "text"
      },
      "source": [
        "## Unsupervised Pretraining\n",
        "\n",
        "In the code below, we create a neural network for MNIST classification. We first train it alone and see how it performs. Next, we train it again using the features that the unsupervised autoencoder learned and see how the performance compares to when we just did the supervised training alone.\n",
        "\n",
        "In 2006 Geoffrey Hinton et al. discovered that DNNs can be pretrained using unsupervised learning. They used restricted Boltzmann machines (RBFs) but Yoshua Bengio et al. showed that autoencoders worked just as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z5fAH1rxrIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the graph for both training techniques.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_outputs = 10\n",
        "\n",
        "learning_rate = 0.01\n",
        "l2_reg = 0.00005\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "y = tf.placeholder(tf.int32, shape=(None))\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
        "\n",
        "init_weights = lambda n1, n2, name: \\\n",
        "    tf.Variable(he_init([n1, n2]), dtype=tf.float32, name=name)\n",
        "W1 = init_weights(n_inputs, n_hidden1, 'weights1')\n",
        "W2 = init_weights(n_hidden1, n_hidden2, 'weights2')\n",
        "W3 = init_weights(n_hidden2, n_hidden2, 'weights3')\n",
        "W4 = init_weights(n_hidden2, n_outputs, 'weights4')\n",
        "\n",
        "# Don't need to redefine init_bias()\n",
        "b1 = init_bias(n_hidden1, name='bias1')\n",
        "b2 = init_bias(n_hidden2, name='bias2')\n",
        "b3 = init_bias(n_hidden2, name='bias3')\n",
        "b4 = init_bias(n_outputs, name='bias4')\n",
        "\n",
        "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
        "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
        "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
        "logits = tf.matmul(hidden3, W4) + b4\n",
        "\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                          logits=logits)\n",
        "reg_loss = regularizer(W1) + regularizer(W2) + regularizer(W3)\n",
        "loss = xentropy + reg_loss\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(loss)\n",
        "pretrain_training_op = opt.minimize(loss, var_list=[W3, b3])\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "pretrain_saver = tf.train.Saver([W1, W2, b1, b2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPqlwp11YEH",
        "colab_type": "code",
        "outputId": "7a0acb7a-2f19-456e-a118-3b8fc4974744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Regular training without pretraining.\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size = 150\n",
        "n_labeled_instances = 20000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = n_labeled_instances // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train accuracy:', acc_val, end=' ')\n",
        "    saver.save(sess, './my_model_supervised.ckpt')\n",
        "    acc_val = accuracy.eval(feed_dict={\n",
        "        X: mnist.test.images,\n",
        "        y: mnist.test.labels,\n",
        "    })\n",
        "    print('Test accuracy:', acc_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.9266667 Test accuracy: 0.932\n",
            "1 Train accuracy: 0.96 Test accuracy: 0.9355\n",
            "2 Train accuracy: 0.97333336 Test accuracy: 0.9345\n",
            "3 Train accuracy: 0.99333334 Test accuracy: 0.9433\n",
            "4 Train accuracy: 0.97333336 Test accuracy: 0.9491\n",
            "5 Train accuracy: 0.98 Test accuracy: 0.9485\n",
            "6 Train accuracy: 0.9866667 Test accuracy: 0.9525\n",
            "7 Train accuracy: 1.0 Test accuracy: 0.9393\n",
            "8 Train accuracy: 0.9866667 Test accuracy: 0.951\n",
            "9 Train accuracy: 0.99333334 Test accuracy: 0.9479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vZigpKb3DTT",
        "colab_type": "code",
        "outputId": "a254c26b-64be-426e-e0d3-797eb3946232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Now using the layers that were pre-trained. This technique both sped\n",
        "# up training and made the model perform better!\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  pretrain_saver.restore(sess, './my_model_cache_frozen.ckpt')\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = n_labeled_instances // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(pretrain_training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train accuracy:', acc_val, end=' ')\n",
        "    saver.save(sess, './my_model_supervised.ckpt')\n",
        "    acc_val = accuracy.eval(feed_dict={\n",
        "        X: mnist.test.images,\n",
        "        y: mnist.test.labels,\n",
        "    })\n",
        "    print('Test accuracy:', acc_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.94666666 Test accuracy: 0.9168\n",
            "1 Train accuracy: 0.94 Test accuracy: 0.9345\n",
            "2 Train accuracy: 0.96 Test accuracy: 0.9429\n",
            "3 Train accuracy: 0.97333336 Test accuracy: 0.9508\n",
            "4 Train accuracy: 0.96666664 Test accuracy: 0.9519\n",
            "5 Train accuracy: 0.9866667 Test accuracy: 0.9558\n",
            "6 Train accuracy: 0.98 Test accuracy: 0.9555\n",
            "7 Train accuracy: 0.99333334 Test accuracy: 0.9584\n",
            "8 Train accuracy: 0.97333336 Test accuracy: 0.9581\n",
            "9 Train accuracy: 0.97333336 Test accuracy: 0.9586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnibmCmwaDZR",
        "colab_type": "text"
      },
      "source": [
        "## Stacked Denoising Autoencoder\n",
        "\n",
        "In a [2008 paper](https://www.iro.umontreal.ca/~vincentp/Publications/denoising_autoencoders_tr1316.pdf) Pascal Vincent et al. showed that autoencoders could be used for feature extraction. A [2010 paper by Vincent et al.](http://jmlr.csail.mit.edu/papers/volume11/vincent10a/vincent10a.pdf) introduced _stacked denoising autoencoders_.\n",
        "\n",
        "You can also add Gaussian noise to the inputs, like in the example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "req1IkPMuHk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "noise_level = 1.0\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "X_noise = X + (noise_level * tf.random_normal(tf.shape(X)))\n",
        "\n",
        "hidden1 = tf.layers.dense(X_noise, n_hidden1, activation=tf.nn.elu)\n",
        "hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.elu)\n",
        "hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.elu)\n",
        "outputs = tf.layers.dense(hidden3, n_outputs)\n",
        "\n",
        "mse = tf.reduce_mean(tf.square(X - outputs))\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59x-Ny54xJub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "057eef09-85a1-48d5-8326-3fcf45c04aca"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    mse_val = mse.eval(feed_dict={X: X_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train MSE:', mse_val)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.037528284\n",
            "1 Train MSE: 0.033405814\n",
            "2 Train MSE: 0.033303495\n",
            "3 Train MSE: 0.033667754\n",
            "4 Train MSE: 0.030195063\n",
            "5 Train MSE: 0.031798024\n",
            "6 Train MSE: 0.029453682\n",
            "7 Train MSE: 0.030101554\n",
            "8 Train MSE: 0.029107567\n",
            "9 Train MSE: 0.028518533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkxlpFw4_RC7",
        "colab_type": "text"
      },
      "source": [
        "Now implementing a denoising stacked autoencoder using dropout:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmLmEWhH_VB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 ** 2\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_hidden3 = n_hidden1\n",
        "n_outputs = n_inputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.3\n",
        "\n",
        "training = tf.placeholder_with_default(False, shape=())\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "X_drop = tf.layers.dropout(X, rate=dropout_rate, training=training)\n",
        "\n",
        "dense = partial(tf.layers.dense, activation=tf.nn.elu)\n",
        "hidden1 = dense(X_drop, n_hidden1)\n",
        "hidden2 = dense(hidden1, n_hidden2)\n",
        "hidden3 = dense(hidden2, n_hidden3)\n",
        "outputs = dense(hidden3, n_outputs)\n",
        "\n",
        "mse = tf.reduce_mean(tf.square(X - outputs))\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = opt.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCRUDv0A5yq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b6748970-5b0b-4e79-b98b-bf24c0f82656"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for i in range(n_batches):\n",
        "      print('\\r{}%'.format(100 * i // n_batches), end='')\n",
        "      sys.stdout.flush()\n",
        "      indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
        "      X_batch, y_batch = \\\n",
        "          mnist.train.images[indices], mnist.train.labels[indices]\n",
        "      sess.run(training_op, feed_dict={X: X_batch})\n",
        "    mse_val = mse.eval(feed_dict={X: X_batch})\n",
        "    print('\\r{}'.format(epoch), 'Train MSE:', mse_val)\n",
        "    saver.save(sess, './my_model_stacked_denoising_dropout.ckpt')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train MSE: 0.007448957\n",
            "1 Train MSE: 0.0053716255\n",
            "2 Train MSE: 0.004941396\n",
            "3 Train MSE: 0.004768422\n",
            "4 Train MSE: 0.00451429\n",
            "5 Train MSE: 0.004599574\n",
            "6 Train MSE: 0.00441814\n",
            "7 Train MSE: 0.0044791354\n",
            "8 Train MSE: 0.0045385733\n",
            "9 Train MSE: 0.004469487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbiCLnRWBRFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "b5922f30-5c1b-475a-9f01-1f18899fa9c7"
      },
      "source": [
        "show_reconstructed_digits(\n",
        "    X, outputs, './my_model_stacked_denoising_dropout.ckpt')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAD/CAYAAACDzAGWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/g/gsgajx5elIgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}