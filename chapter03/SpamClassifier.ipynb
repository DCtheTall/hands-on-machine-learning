{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamClassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-wuxo032e5C5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Exercise 4\n",
        "## Build an Email Spam Classifier\n",
        "\n",
        "This is based on the solution [here](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb), which I reimplemented as an educational exercise.\n",
        "\n",
        "### Downloading the Data"
      ]
    },
    {
      "metadata": {
        "id": "3d6RbNBGkGFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining a function to get the data, taken from solution.\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_URL = 'https://spamassassin.apache.org/old/publiccorpus/'\n",
        "HAM_URL = DOWNLOAD_URL + '20021010_easy_ham.tar.bz2'\n",
        "SPAM_URL = DOWNLOAD_URL + '20021010_spam.tar.bz2'\n",
        "SPAM_PATH = os.path.join('datasets', 'spam')\n",
        "\n",
        "def fetch_data():\n",
        "  if not os.path.isdir(SPAM_PATH):\n",
        "    os.makedirs(SPAM_PATH)\n",
        "  for fname, url in [('ham.tar.bz2', HAM_URL), ('spam.tar.bz2', SPAM_URL)]:\n",
        "    path = os.path.join(SPAM_PATH, fname)\n",
        "    if not os.path.isfile(path):\n",
        "      urllib.request.urlretrieve(url, path)\n",
        "    tar_bz2_file = tarfile.open(path)\n",
        "    tar_bz2_file.extractall(path=SPAM_PATH)\n",
        "    tar_bz2_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0xXRojhmnvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fetch_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VslQIxA5mwEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting a list of the filenames\n",
        "\n",
        "HAM_DIR = os.path.join(SPAM_PATH, 'easy_ham')\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, 'spam')\n",
        "\n",
        "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR))\n",
        "                 if len(name) > 20]\n",
        "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR))\n",
        "                  if len(name) > 20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xd2xl8awnmsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0eb61678-ab9f-41c0-af54-4cc3daa8dbfa"
      },
      "cell_type": "code",
      "source": [
        "print('Number of ham:', len(ham_filenames))\n",
        "print('Number of spam:', len(spam_filenames))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of ham: 2551\n",
            "Number of spam: 501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYBokiOFoAG7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Parsing the Emails in the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "6KiywokboCrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define an email parsing function, taken from solution.\n",
        "\n",
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
        "  directory = 'spam' if is_spam else 'easy_ham'\n",
        "  with open(os.path.join(spam_path, directory, filename), 'rb') as f:\n",
        "    return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6W_I5eIrNwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Opening and parsing the email files.\n",
        "\n",
        "ham_emails = [load_email(is_spam=False, filename=fname)\n",
        "              for fname in ham_filenames]\n",
        "spam_emails = [load_email(is_spam=True, filename=fname)\n",
        "               for fname in spam_filenames][1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DT93HGyGr_b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "a345d7e3-021c-4b8d-c591-4bbad0293e1e"
      },
      "cell_type": "code",
      "source": [
        "# Example of ham.\n",
        "\n",
        "print(ham_emails[1].get_content().strip())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Martin A posted:\n",
            "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
            " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
            " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
            " \n",
            " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
            " museum, a restored amphitheatre and car park for admiring crowds are\n",
            "planned\n",
            "---------------------\n",
            "So is this mountain limestone or granite?\n",
            "If it's limestone, it'll weather pretty fast.\n",
            "\n",
            "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
            "4 DVDs Free +s&p Join Now\n",
            "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
            "---------------------------------------------------------------------~->\n",
            "\n",
            "To unsubscribe from this group, send an email to:\n",
            "forteana-unsubscribe@egroups.com\n",
            "\n",
            " \n",
            "\n",
            "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EqnQ-Q1vsK38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "86a40c6e-ce01-4018-fc20-0368d436fe29"
      },
      "cell_type": "code",
      "source": [
        "# Example of spam.\n",
        "\n",
        "print(spam_emails[6].get_content().strip())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
            "growing at a tremendous rate.  We are looking for individuals who\n",
            "want to work from home.\n",
            "\n",
            "This is an opportunity to make an excellent income.  No experience\n",
            "is required.  We will train you.\n",
            "\n",
            "So if you are looking to be employed from home with a career that has\n",
            "vast opportunities, then go:\n",
            "\n",
            "http://www.basetel.com/wealthnow\n",
            "\n",
            "We are looking for energetic and self motivated people.  If that is you\n",
            "than click on the link and fill out the form, and one of our\n",
            "employement specialist will contact you.\n",
            "\n",
            "To be removed from our link simple go to:\n",
            "\n",
            "http://www.basetel.com/remove.html\n",
            "\n",
            "\n",
            "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "03q0inCgsvIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function for breaking down the email structure.\n",
        "\n",
        "def get_email_structure(email):\n",
        "  if isinstance(email, str):\n",
        "    return email\n",
        "  payload = email.get_payload()\n",
        "  if isinstance(payload, list):\n",
        "    return 'multipart({})'.format(', '.join(\n",
        "        get_email_structure(sub_email)\n",
        "        for sub_email in payload\n",
        "    ))\n",
        "  return email.get_content_type()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fcEhtW4YuqFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use the Counter class to keep track of how many emails\n",
        "# have a given structure.\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_structures(emails):\n",
        "  structures = Counter()\n",
        "  for email in emails:\n",
        "    struct = get_email_structure(email)\n",
        "    structures[struct] += 1\n",
        "  return structures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8O64QS69x7Ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0d8a76ca-c371-420d-85fb-55be3e387db1"
      },
      "cell_type": "code",
      "source": [
        "count_structures(ham_emails).most_common()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2453),\n",
              " ('multipart(text/plain, application/pgp-signature)', 72),\n",
              " ('multipart(text/plain, text/html)', 8),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "McZ5l0YOyL6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1945aacb-e387-46c2-dc0e-36abbbfab73e"
      },
      "cell_type": "code",
      "source": [
        "count_structures(spam_emails).most_common()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 221),\n",
              " ('text/html', 181),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 19),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "WQivcbIvyakn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "097330f4-fc9f-4977-bca7-ca5f5a6bc0d7"
      },
      "cell_type": "code",
      "source": [
        "# Taking the look at the headers in the spam emails.\n",
        "\n",
        "for header, value in spam_emails[0].items():\n",
        "  print(header + ':', value)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Return-Path: <12a1mailbot1@web.de>\n",
            "Delivered-To: zzzz@localhost.example.com\n",
            "Received: from localhost (localhost [127.0.0.1])\tby phobos.labs.example.com (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
            "Received: from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
            "Received: from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@example.com>; Thu, 22 Aug 2002 13:09:41 +0100\n",
            "From: 12a1mailbot1@web.de\n",
            "Received: from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
            "To: dcek1a1@netsgo.com\n",
            "Subject: Life Insurance - Why Pay More?\n",
            "Date: Wed, 21 Aug 2002 20:31:57 -1600\n",
            "MIME-Version: 1.0\n",
            "Message-ID: <0103c1042001882DD_IT7@dd_it7>\n",
            "Content-Type: text/html; charset=\"iso-8859-1\"\n",
            "Content-Transfer-Encoding: quoted-printable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x94nwg-VzQXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Splitting the data into a train and test set.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                   random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMkGe3880THp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parsing the HTML in the emails into plaintext.\n",
        "\n",
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plaintext(html):\n",
        "  text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "  text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "  text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "  text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "  return unescape(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDLJDIk22NVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "2c3b1cda-a563-42b5-fd2a-f879b4c80405"
      },
      "cell_type": "code",
      "source": [
        "# An example of HTML spam.\n",
        "\n",
        "html_spam_emails = [email for email in X_train[y_train == 1]\n",
        "                    if get_email_structure(email) == 'text/html']\n",
        "sample_html_spam = html_spam_emails[8]\n",
        "print(sample_html_spam.get_content().strip(), '...')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n",
            "<HTML>\n",
            "\n",
            "<HEAD>\n",
            "\t<META NAME=\"GENERATOR\" Content=\"Visual Page 1.0 for Windows\">\n",
            "\t<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html;CHARSET=iso-8859-1\">\n",
            "\t<TITLE>untitled</TITLE>\n",
            "</HEAD>\n",
            "\n",
            "<BODY onLoad=\"(window.open('http://sam.hostcentrel.com/norton/'))\">\n",
            "\n",
            "<P ALIGN=\"CENTER\"><FONT COLOR=\"#0000FF\" face=\"Arial\"><B>ATTENTION: This is a MUST for ALL Computer Users!!!<BR>\n",
            "</B></FONT><FONT COLOR=\"#000000\" face=\"Arial\"><BR>\n",
            "</FONT><FONT face=\"Arial\"><B>*NEW-Special Package Deal!*<BR>\n",
            "</B></FONT><FONT COLOR=\"#000000\" face=\"Arial\"><BR>\n",
            "</FONT><FONT COLOR=\"#FF0000\" face=\"Arial\"><B>Norton SystemWorks 2002 Software Suite -Professional Edition-\n",
            "\n",
            "Includes Six - Yes 6! - Feature-Packed Utilities\n",
            "ALL For 1 Special LOW Price!6 Feature-Packed Utilities...1 Great Price!\n",
            "A $300+ Combined Retail Value!\n",
            "\n",
            "FREE Shipping!</B></FONT></P>\n",
            "\n",
            "<P ALIGN=\"CENTER\"><FONT COLOR=\"#FF0000\" face=\"Arial\"><B><BR>\n",
            "</B></FONT><A HREF=\"http://sam.hostcentrel.com/norton/\"><FONT face=\"Arial\"><B>Click Here Now!</B></FONT></A>\n",
            "\n",
            "\n",
            "</BODY>\n",
            "\n",
            "</HTML> ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w5WU3XoI3qvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4ac37588-6db9-443a-b405-22722ed147ca"
      },
      "cell_type": "code",
      "source": [
        "print(html_to_plaintext(sample_html_spam.get_content().strip()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ATTENTION: This is a MUST for ALL Computer Users!!!\n",
            "*NEW-Special Package Deal!*\n",
            "Norton SystemWorks 2002 Software Suite -Professional Edition-\n",
            "Includes Six - Yes 6! - Feature-Packed Utilities\n",
            "ALL For 1 Special LOW Price!6 Feature-Packed Utilities...1 Great Price!\n",
            "A $300+ Combined Retail Value!\n",
            "FREE Shipping!\n",
            " HYPERLINK Click Here Now!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TmUOSeuLNXTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining a function which returns the text content of the email.\n",
        "\n",
        "def email_to_text(email):\n",
        "  html = None\n",
        "  for part in email.walk():\n",
        "    ctype = part.get_content_type()\n",
        "    if not ctype in ('text/plain', 'text/html'):\n",
        "      continue\n",
        "    try:\n",
        "      content = part.get_content()\n",
        "    except:\n",
        "      content = str(part.get_payload())\n",
        "    if ctype == 'text/plain':\n",
        "      return content\n",
        "    html = content\n",
        "  if html:\n",
        "    return html_to_plaintext(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7AJGF8wGohY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "24fecc4d-9938-42d5-c773-247303884557"
      },
      "cell_type": "code",
      "source": [
        "print(email_to_text(sample_html_spam))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ATTENTION: This is a MUST for ALL Computer Users!!!\n",
            "*NEW-Special Package Deal!*\n",
            "Norton SystemWorks 2002 Software Suite -Professional Edition-\n",
            "Includes Six - Yes 6! - Feature-Packed Utilities\n",
            "ALL For 1 Special LOW Price!6 Feature-Packed Utilities...1 Great Price!\n",
            "A $300+ Combined Retail Value!\n",
            "FREE Shipping!\n",
            " HYPERLINK Click Here Now!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QbDXicKbLuU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1d1a818f-a3b3-47cd-961b-1a4e361c7fcc"
      },
      "cell_type": "code",
      "source": [
        "# Create a PorterStemmer to transform words into their stems.\n",
        "\n",
        "import nltk\n",
        "\n",
        "stemmer = nltk.PorterStemmer()\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\",\n",
        "             \"Compulsive\"):\n",
        "  print(word, '=>', stemmer.stem(word))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R2F7KeBEMrBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c29ad5bc-38c7-4fe5-af5d-040268ece8ba"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install urlextract"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: urlextract in /usr/local/lib/python3.6/dist-packages (0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from urlextract) (2.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from urlextract) (1.4.3)\n",
            "Requirement already satisfied: uritools in /usr/local/lib/python3.6/dist-packages (from urlextract) (2.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0W9TY3DsM-nE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff48046a-ec2c-4b98-d98e-9e446b67f782"
      },
      "cell_type": "code",
      "source": [
        "# Instantiating the URLExtract class from the urlextract module.\n",
        "\n",
        "import urlextract\n",
        "\n",
        "url_extractor = urlextract.URLExtract()\n",
        "print(url_extractor.find_urls(\n",
        "    \"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Guoo-R71H5yV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Putting it together into a Scikit-Learn transformer, taken from solution.\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCountTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, lower_case=True, replace_urls=True, replace_numbers=True,\n",
        "               replace_punctuation=True, stemming=True):\n",
        "    self.lower_case = lower_case\n",
        "    self.replace_urls = replace_urls\n",
        "    self.replace_numbers = replace_numbers\n",
        "    self.replace_punctuation = replace_punctuation\n",
        "    self.stemming = stemming\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    X_transformed = []\n",
        "    for email in X:\n",
        "      text = email_to_text(email) or ''\n",
        "      if self.lower_case:\n",
        "        text = text.lower()\n",
        "      if self.replace_urls:\n",
        "        urls = list(set(url_extractor.find_urls(text)))\n",
        "        urls.sort(key=lambda url: len(url), reverse=True)\n",
        "        for url in urls:\n",
        "          text = text.replace(url, ' URL ')\n",
        "      if self.replace_numbers:\n",
        "        text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
        "      if self.replace_punctuation:\n",
        "        text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "      word_counts = Counter(text.split())\n",
        "      if self.stemming:\n",
        "        stemmed_word_counts = Counter()\n",
        "        for word, count in word_counts.items():\n",
        "          stem = stemmer.stem(word)\n",
        "          stemmed_word_counts[stem] += count\n",
        "        word_counts = stemmed_word_counts\n",
        "      X_transformed.append(word_counts)\n",
        "    return np.array(X_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cl9KresuLGUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ad0254a9-879f-447e-9859-543c985c650d"
      },
      "cell_type": "code",
      "source": [
        "# Testing out EmailToWordCountTransformer.\n",
        "\n",
        "X_few = X_train[:3]\n",
        "X_few_wordcounts = EmailToWordCountTransformer().fit_transform(X_few)\n",
        "print(X_few_wordcounts)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Counter({'it': 4, 'pay': 3, 't': 3, 'the': 2, 'you': 2, 'without': 2, 's': 2, 'i': 2, 'a': 2, 'can': 2, 'look': 2, 'at': 2, 'if': 1, 'creator': 1, 'didnt': 1, 'say': 1, 'could': 1, 'have': 1, 'theft': 1, 'so': 1, 'simpl': 1, 'hell': 1, 'that': 1, 'even': 1, 'in': 1, 'all': 1, 'major': 1, 'holi': 1, 'book': 1, 'wow': 1, 've': 1, 'got': 1, 'great': 1, 'idea': 1, 'll': 1, 'hire': 1, 'skywrit': 1, 'to': 1, 'write': 1, 'thi': 1, 'then': 1, 'lock': 1, 'up': 1, 'everybodi': 1, 'who': 1, 'and': 1, 'didn': 1, 'fail': 1, 'jesu': 1, 'is': 1, 'on': 1, 'my': 1, 'side': 1, 'url': 1})\n",
            " Counter({'number': 8, 'i': 8, 'to': 5, 'the': 5, 'url': 4, 'of': 4, 'we': 3, 'realli': 3, 'look': 3, 'it': 3, 'that': 3, 'with': 3, 'date': 2, 't': 2, 'but': 2, 'is': 2, 'what': 2, 'would': 2, 'time': 2, 'for': 2, 'a': 2, 'have': 2, 'm': 2, 'not': 2, 'will': 2, 'tue': 1, 'aug': 1, 'from': 1, 'brent': 1, 'welch': 1, 'messag': 1, 'id': 1, 'if': 1, 'are': 1, 'allow': 1, 'assum': 1, 'or': 1, 'higher': 1, 'which': 1, 'can': 1, 'then': 1, 'could': 1, 'add': 1, 'selecttypein': 1, 'procedur': 1, 'ye': 1, 'at': 1, 'fix': 1, 'there': 1, 'code': 1, 'quit': 1, 'gener': 1, 'almost': 1, 'no': 1, 'understand': 1, 'anyth': 1, 'mean': 1, 'so': 1, 'didn': 1, 'think': 1, 'corrupt': 1, 'knowlwedg': 1, 'semant': 1, 'fetch': 1, 'be': 1, 'best': 1, 'thing': 1, 'do': 1, 'ran': 1, 'out': 1, 'last': 1, 'night': 1, 'while': 1, 'better': 1, 'place': 1, 'similar': 1, 'check': 1, 'gone': 1, 'directli': 1, 'regexp': 1, 'up': 1, 'all': 1, 'latest': 1, 'tcl': 1, 'chang': 1, 'and': 1, 'sure': 1, 'today': 1, 'keep': 1, 'kre': 1, '_______________________________________________': 1, 'exmh': 1, 'worker': 1, 'mail': 1, 'list': 1})\n",
            " Counter({'in': 6, 'all': 3, 'her': 2, 'our': 2, 'watch': 2, 'as': 2, 'hyperlink': 2, 'free': 2, 'thi': 1, 'week': 1, 'sydney': 1, 'bare': 1, 'the': 1, 'park': 1, 'join': 1, 'live': 1, 'teen': 1, 'chat': 1, 'sandi': 1, 'strip': 1, 'nake': 1, 'dorm': 1, 'best': 1, 'of': 1, 'see': 1, 'it': 1, 'number': 1, 'don': 1, 't': 1, 'miss': 1, 'out': 1, 'awe': 1, 'stacey': 1, 'suck': 1, 'start': 1, 'ken': 1, 'and': 1, 'bonu': 1, 'pam': 1, 'tommi': 1, 'uncut': 1, 'penthous': 1, 'forum': 1, 'stori': 1, 'jenna': 1, 'jamieson': 1, 'jennamaxx': 1, 'get': 1, 'here': 1, 'for': 1, 'now': 1})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTgE16G6LeLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building a transformer to turn the word counts into a vector.\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, vocabulary_size=1000):\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "  def fit(self, X, y=None):\n",
        "    total_count = Counter()\n",
        "    for word_count in X:\n",
        "      for word, count in word_count.items():\n",
        "        total_count[word] += min(count, 10)\n",
        "    most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "    self.most_common_ = most_common\n",
        "    self.vocabulary_ = {word: i + 1 for i, (word, _) in enumerate(most_common)}\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    rows, cols, data = [], [], []\n",
        "    for row, word_count in enumerate(X):\n",
        "      for word, count in word_count.items():\n",
        "        rows.append(row)\n",
        "        cols.append(self.vocabulary_.get(word, 0))\n",
        "        data.append(count)\n",
        "    return csr_matrix((data, (rows, cols)),\n",
        "                      shape=(len(X), self.vocabulary_size + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAn9bgNhSRZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bd4734d7-6b81-4ed7-d09c-73675a2f3614"
      },
      "cell_type": "code",
      "source": [
        "# Testing out WordCounterToVectorTransformer.\n",
        "\n",
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "print(X_few_vectors.toarray())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 53   2   0   2   4   1   1   3   1   2   1]\n",
            " [109   8   8   5   3   0   5   2   1   3   4]\n",
            " [ 51   0   1   1   1   6   0   1   3   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KPwQnocpSzlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "822ad2f2-f36f-44d5-a900-ea09682ccfc3"
      },
      "cell_type": "code",
      "source": [
        "vocab_transformer.vocabulary_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all': 8,\n",
              " 'i': 1,\n",
              " 'in': 5,\n",
              " 'it': 4,\n",
              " 'look': 9,\n",
              " 'number': 2,\n",
              " 't': 7,\n",
              " 'the': 3,\n",
              " 'to': 6,\n",
              " 'url': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "t4tLlfDES2vp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building a preprocessing Pipeline for the model.\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "    ('email_to_wordcount', EmailToWordCountTransformer()),\n",
        "    ('word_count_to_vector', WordCounterToVectorTransformer()),\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9B8b_9XUTxfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "483410fe-93ec-49e4-85ee-581071bf6304"
      },
      "cell_type": "code",
      "source": [
        "# Testing out LogisticRegression on the data, getting over 98.6% accuracy.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
        "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] ....................... , score=0.9889434889434889, total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ........................ , score=0.990159901599016, total=   0.2s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........................ , score=0.981549815498155, total=   0.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9868844020135533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "y0CsKeVcUilF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1a5d78d-dc37-4f41-b7b0-5dc6956bf1ef"
      },
      "cell_type": "code",
      "source": [
        "# Measuring precision and recall on the test set.\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "log_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "\n",
        "y_pred = log_clf.predict(X_test_transformed)\n",
        "\n",
        "print('Precision score: {:.2f}'.format(100 * precision_score(y_test, y_pred)))\n",
        "print('Recall score: {:.2f}'.format(100 * recall_score(y_test, y_pred)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 93.81\n",
            "Recall score: 95.79\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}