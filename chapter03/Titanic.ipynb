{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HppvVIP5eIbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Titanic Dataset\n",
        "Exercise 4 of Chapter 2 is to build a classifier for the\n",
        "[Titanic Kaggle problem](https://www.kaggle.com/c/titanic).\n",
        "\n",
        "The first step is to download the data:"
      ]
    },
    {
      "metadata": {
        "id": "jnWAKn7Oe_4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installing the Kaggle API\n",
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p /root/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBEsCaeQf2rw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Uploading the installed files using google.colab module from\n",
        "# my machine.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z9GcEFaTgVPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copying the API key.\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfoTfNsZn5WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DF0mGiTuu_lL",
        "colab_type": "code",
        "outputId": "b98db3be-d833-4555-a636-542cbb76f1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions list"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2462           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      10016            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4066           False  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         35           False  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2450           False  \n",
            "two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       1466           False  \n",
            "tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        310           False  \n",
            "dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag        880           False  \n",
            "data-science-for-good-careervillage            2019-04-23 23:59:00  Analytics          $15,000          0           False  \n",
            "gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        294           False  \n",
            "santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       3561           False  \n",
            "womens-machine-learning-competition-2019       2019-04-09 23:59:00  Featured           $25,000        137           False  \n",
            "mens-machine-learning-competition-2019         2019-04-08 23:59:00  Featured           $25,000        230           False  \n",
            "histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge        788           False  \n",
            "petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       1450           False  \n",
            "vsb-power-line-fault-detection                 2019-03-21 23:59:00  Featured           $25,000       1151           False  \n",
            "microsoft-malware-prediction                   2019-03-13 23:59:00  Research           $25,000       2132           False  \n",
            "humpback-whale-identification                  2019-02-28 23:59:00  Featured           $25,000       2131           False  \n",
            "elo-merchant-category-recommendation           2019-02-26 23:59:00  Featured           $50,000       4128           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d-pkEW0IwEEB",
        "colab_type": "code",
        "outputId": "61997259-fd99-46dc-d382-206a3370814e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions files -c titanic"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name                   size  creationDate         \n",
            "---------------------  ----  -------------------  \n",
            "train.csv              60KB  2013-06-28 13:40:25  \n",
            "test.csv               28KB  2013-06-28 13:40:24  \n",
            "gender_submission.csv   3KB  2017-02-01 01:49:18  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y75LNc9QyXJt",
        "colab_type": "code",
        "outputId": "e8fad5e2-e043-4086-950f-00882badf2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the data into the Colab.\n",
        "\n",
        "!kaggle competitions download  -c titanic -p /content/kaggle"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv to /content/kaggle\n",
            "\r  0% 0.00/59.8k [00:00<?, ?B/s]\n",
            "100% 59.8k/59.8k [00:00<00:00, 24.3MB/s]\n",
            "Downloading test.csv to /content/kaggle\n",
            "  0% 0.00/28.0k [00:00<?, ?B/s]\n",
            "100% 28.0k/28.0k [00:00<00:00, 25.9MB/s]\n",
            "Downloading gender_submission.csv to /content/kaggle\n",
            "  0% 0.00/3.18k [00:00<?, ?B/s]\n",
            "100% 3.18k/3.18k [00:00<00:00, 2.51MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BVKo6tskKpca",
        "colab_type": "code",
        "outputId": "75d5fc72-42c9-4ae4-973c-5b940b2a7926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./kaggle/train.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "metadata": {
        "id": "J2s_PcoEPK01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class for selecting features from the DataFrame.\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "        \n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "    \n",
        "  def transform(self, X, y=None):\n",
        "    return X[self.attribute_names].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-62SHj0jt1Q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
        "                                        index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fjnmll2MN8cP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preparing the dataset with some pipelines.\n",
        "\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y_train = df['Survived']\n",
        "\n",
        "num_attribs = ['PassengerId', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "cat_attribs = ['Pclass', 'Sex', 'Embarked', 'Cabin']\n",
        "str_attribs = ['Name', 'Ticket']\n",
        "\n",
        "# Transformer for numerical attributes\n",
        "num_pipeline = Pipeline([\n",
        "    ('num_attrib_selector', DataFrameSelector(num_attribs)),\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('cat_attrib_selector', DataFrameSelector(cat_attribs)),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('one_hot_encoder', OneHotEncoder(categories='auto', sparse=False)),\n",
        "])\n",
        "\n",
        "feature_pipeline = FeatureUnion(transformer_list=[\n",
        "    ('num_pipeline', num_pipeline),\n",
        "    ('cat_pipeline', cat_pipeline),\n",
        "])\n",
        "\n",
        "X_train = feature_pipeline.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8J94X5CXRSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef07dac9-72d3-4da0-d6ef-84baab1244ce"
      },
      "cell_type": "code",
      "source": [
        "# First trying Stochastic Gradient Descent, which gets 70%-85% accuracy.\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(SGDClassifier(max_iter=1e3, tol=1e-3), X_train, y_train, cv=5)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7150838 , 0.70949721, 0.75280899, 0.78089888, 0.70621469])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "metadata": {
        "id": "_TseFfqcda3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a952e74d-792e-41cd-9860-fa87b86b6262"
      },
      "cell_type": "code",
      "source": [
        "# Trying a RandomForestClassifier, a more complex model,\n",
        "# it appears to improve the accuracy, suggesting that\n",
        "# the previous model was underfitting slightly.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cross_val_score(\n",
        "    RandomForestClassifier(n_estimators=100, max_features=5), X_train, y_train, cv=5)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.74301676, 0.7877095 , 0.85393258, 0.83707865, 0.85875706])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "metadata": {
        "id": "6jWh-V5MgIDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3bd03c2-8719-45f9-f68e-e04d360fa423"
      },
      "cell_type": "code",
      "source": [
        "# Grid searching using RandomForestClassifier. The best model\n",
        "# gets 81%-82% accuracy, as good as the author's solution.\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{\n",
        "    'n_estimators': [10, 100],\n",
        "    'max_features': [5, 10, 15],\n",
        "}]\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_features': 10, 'n_estimators': 100}\n",
            "0.813692480359147\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}