{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MsPacMan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsJvFUW9I4wq",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 16: Reinforcement Learning\n",
        "\n",
        "## Learning to Play Ms. Pac-Man Using the DQN Algorithm\n",
        "\n",
        "Given a game that can be described using a [Markov Decision Process](https://goo.gl/wZTVIN), e.g. Ms. Pac-Man, we want to train an RL model which can learn what actions the agent can take which will yield the most rewards.\n",
        "\n",
        "We will do so by training a _deep Q-network_ (DQN) to learn how to approximate the Q-Values of each state-action pair by learning a function to get approximate Q-Values, $Q_\\theta (s, a)$, where $\\theta$ is the learned model parameters. In this case, the state is the raw pixels of the Pac-Man game and the actions are the 9 directions you can move the joystick.\n",
        "\n",
        "The model is trained using Gradient Descent where the target Q-Values for each state-action pair is given by\n",
        "\n",
        "$$ y(s, a) = r \\, + \\, \\gamma \\cdot \\max_{a'} \\, Q_\\theta\\left(s',a'\\right) $$\n",
        "\n",
        "where\n",
        "\n",
        "- $r$ is the reward that the agent gets from taking action $a$ when the game is in state $s$.\n",
        "\n",
        "- $\\gamma$ is the discount rate.\n",
        "\n",
        "For more information about Q-Learning and DQNs, see `ReinforcementLearning.ipynb`.\n",
        "\n",
        "## Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqM5MCZwHxRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def reset_graph(seed=42):\n",
        "  tf.reset_default_graph()\n",
        "  tf.set_random_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghld4_FbXXqD",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Ms. Pac-Man Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVoLoRMX6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('MsPacman-v0')\n",
        "obs = env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBIlxPjYHtt",
        "colab_type": "code",
        "outputId": "96c70c4c-0632-47d6-fbb3-cd4e45206893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# (height, width, channels)\n",
        "obs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx-b0VdOYROG",
        "colab_type": "code",
        "outputId": "347371fb-826a-483f-cd92-ada174edf62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NlHiFsBYZ3t",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Since the image for the game state is large and contains RGB channels, we want to define a preprocessing function which will reduce the image's size, make it grayscale, and increase the contrast of Ms. Pac-Man. This will speed up training and reduce the amount of computations the DQN will need to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXjRrm7LY7Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mspacman_color = np.array([210, 164, 74]).mean()\n",
        "\n",
        "def preprocess_observation(obs):\n",
        "  img = obs[1:176:2, ::2] # crop and downsize\n",
        "  img = img.mean(axis=2) # convert to grayscale\n",
        "  img[img == mspacman_color] = 0 # improve contrast\n",
        "  img = (img - 128) / 128 # normalize values from -1 to 1.\n",
        "  return img.reshape(88, 80, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOO1uV9a95E",
        "colab_type": "code",
        "outputId": "c44eb794-df39-4d93-9f0f-593203b08fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# Plotting the original image and the preprocessed image next to each other.\n",
        "\n",
        "plt.figure(figsize=(11, 7))\n",
        "plt.subplot(121)\n",
        "plt.title('Original Observation (160 x 210 RGB)')\n",
        "plt.imshow(obs)\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.title('Preprocessed Observation (80 x 88 Grayscale)')\n",
        "img = preprocess_observation(obs)\n",
        "plt.imshow(img.reshape(88, 80), interpolation='nearest', cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAGgCAYAAAAZ0oddAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElqYiApSZKkJv8fqfWlxxPIfpkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 792x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6BRqMCIdtfT",
        "colab_type": "text"
      },
      "source": [
        "## Build the DQN\n",
        "\n",
        "The DQN will be composed of 3 convolutional layers, a hidden fully connected layer, and then finally an output layer with 9 neurons, one for each action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5KPHTQvdvLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "input_height = 88\n",
        "input_width = 80\n",
        "input_channels = 1\n",
        "conv_n_maps = [32, 64, 64]\n",
        "conv_kernel_sizes = [(8, 8), (4, 4), (3, 3)]\n",
        "conv_strides = [4, 2, 1]\n",
        "conv_paddings = ['SAME'] * 3\n",
        "conv_activation = [tf.nn.relu] * 3\n",
        "n_hidden_in = 64 * 11 * 10\n",
        "n_hidden = 512\n",
        "hidden_activation = tf.nn.relu\n",
        "n_outputs = env.action_space.n\n",
        "initializer = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YslHhDUoGJV",
        "colab_type": "text"
      },
      "source": [
        "This model actually will use two DQNs. The first is the _online_ DQN which learns and plays after each training iteration. The second is the _target_ DQN which generates the target Q-Values. Every few training iterations, the online DQNs parameters are copied to the target DQN. This technique was introduced by DeepMind.\n",
        "\n",
        "Below is a function which generates a DQN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6muWUtaqpRZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def q_network(X_state, name):\n",
        "  prev_layer = X_state\n",
        "  with tf.variable_scope(name) as scope:\n",
        "    for n_maps, kernel_size, strides, padding, activation in zip(\n",
        "        conv_n_maps, conv_kernel_sizes, conv_strides, conv_paddings,\n",
        "        conv_activation):\n",
        "      prev_layer = tf.layers.conv2d(prev_layer, filters=n_maps,\n",
        "                                    kernel_size=kernel_size, strides=strides,\n",
        "                                    padding=padding, activation=activation,\n",
        "                                    kernel_initializer=initializer)\n",
        "    flattened = tf.reshape(prev_layer, [-1, n_hidden_in])\n",
        "    hidden = tf.layers.dense(flattened, n_hidden, activation=hidden_activation,\n",
        "                             kernel_initializer=initializer)\n",
        "    outputs = tf.layers.dense(hidden, n_outputs, kernel_initializer=initializer)\n",
        "  trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "                                     scope=scope.name)\n",
        "  trainable_vars_by_name = {var.name[len(scope.name):]: var\n",
        "                            for var in trainable_vars}\n",
        "  return outputs, trainable_vars_by_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM9FsC5rvk52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Starting the DQN definition.\n",
        "\n",
        "X_state = tf.placeholder(tf.float32, shape=(None, input_height, input_width,\n",
        "                                            input_channels))\n",
        "online_q_values, online_vars = q_network(X_state, 'q_networks/online')\n",
        "target_q_values, target_vars = q_network(X_state, 'q_networks/target')\n",
        "copy_ops = [var.assign(online_vars[name]) for name, var in target_vars.items()]\n",
        "copy_online_to_target = tf.group(*copy_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIexN1vawcZn",
        "colab_type": "code",
        "outputId": "216ba933-32df-4760-ce74-542a29417651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "online_vars"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/conv2d/bias:0': <tf.Variable 'q_networks/online/conv2d/bias:0' shape=(32,) dtype=float32_ref>,\n",
              " '/conv2d/kernel:0': <tf.Variable 'q_networks/online/conv2d/kernel:0' shape=(8, 8, 1, 32) dtype=float32_ref>,\n",
              " '/conv2d_1/bias:0': <tf.Variable 'q_networks/online/conv2d_1/bias:0' shape=(64,) dtype=float32_ref>,\n",
              " '/conv2d_1/kernel:0': <tf.Variable 'q_networks/online/conv2d_1/kernel:0' shape=(4, 4, 32, 64) dtype=float32_ref>,\n",
              " '/conv2d_2/bias:0': <tf.Variable 'q_networks/online/conv2d_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
              " '/conv2d_2/kernel:0': <tf.Variable 'q_networks/online/conv2d_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
              " '/dense/bias:0': <tf.Variable 'q_networks/online/dense/bias:0' shape=(512,) dtype=float32_ref>,\n",
              " '/dense/kernel:0': <tf.Variable 'q_networks/online/dense/kernel:0' shape=(7040, 512) dtype=float32_ref>,\n",
              " '/dense_1/bias:0': <tf.Variable 'q_networks/online/dense_1/bias:0' shape=(9,) dtype=float32_ref>,\n",
              " '/dense_1/kernel:0': <tf.Variable 'q_networks/online/dense_1/kernel:0' shape=(512, 9) dtype=float32_ref>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj0B-x4RqvH4",
        "colab_type": "text"
      },
      "source": [
        "Below we define the training operation for the DQN. First, we need to define its computed Q-Value for each state-action pair. Since the neural network produces a Q-Value for each possible action, we will want to input what the actual action the agent took in a one-hot encoded vector, this way we only compute the Q-Value for the action that was taken.\n",
        "\n",
        "Another modification is that instead of just using MSE for the error, we use a linear error for any loss values less than -1 or greater than 1. This helps training the model since it prevents large loss values from dominating the error gradient.\n",
        "\n",
        "For training, we use Nesterov Accelerated Gradient Descent to train the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFipnucupL84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-3\n",
        "momentum = 0.95\n",
        "\n",
        "with tf.variable_scope('training'):\n",
        "  X_action = tf.placeholder(tf.int32, shape=(None,))\n",
        "  y = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "  q_value = tf.reduce_sum(online_q_values * tf.one_hot(X_action, n_outputs),\n",
        "                          axis=1, keepdims=True)\n",
        "  error = tf.abs(y - q_value)\n",
        "  clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
        "  linear_error = 2 * (error - clipped_error)\n",
        "  loss = tf.reduce_mean(tf.square(clipped_error) + linear_error)\n",
        "  \n",
        "  global_step = tf.Variable(0, trainable=False, name='global_step')\n",
        "  optimizer = tf.train.MomentumOptimizer(learning_rate, momentum,\n",
        "                                         use_nesterov=True)\n",
        "  training_op = optimizer.minimize(loss, global_step=global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFZtakXeurIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjhbCU6vE6t",
        "colab_type": "text"
      },
      "source": [
        "To improve the performance of the model, it will use a _replay memory_ that randomly samples a training batch of past experiences. This increases the variance of the model, helping it generalize better and not correlate the agent's actions with recent replays too strongly. This technique was also developed by DeepMind."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vF76k7wH63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory(object):\n",
        "  def __init__(self, maxlen):\n",
        "    self.maxlen = maxlen\n",
        "    self.buf = np.empty(shape=maxlen, dtype=np.object)\n",
        "    self.index = 0\n",
        "    self.length = 0\n",
        "    \n",
        "  def append(self, data):\n",
        "    self.buf[self.index] = data\n",
        "    self.length = min(self.length + 1, maxlen)\n",
        "    self.index = (self.index + 1) % self.maxlen\n",
        "    \n",
        "  def sample(self, batch_size):\n",
        "    return self.buf[np.random.randint(self.length, size=batch_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y5eFB3gxWD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_memory_size = 500000\n",
        "replay_memory = ReplayMemory(replay_memory_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EufMqsnDxe-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_memories(batch_size):\n",
        "  cols = [[], [], [], [], []] # state, action, reward, next_state, continue\n",
        "  for memory in replay_memory.sample(batch_size):\n",
        "    for col, value in zip(cols, memory):\n",
        "      col.append(value)\n",
        "  cols = [np.array(col) for col in cols]\n",
        "  return cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], \\\n",
        "      cols[4].reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fryiSY7rzsvM",
        "colab_type": "text"
      },
      "source": [
        "To allow the model to explore new actions at first then gradually start using the optimal action based on its predicted Q-Value. In order to do so, we will use an $\\varepsilon$-greedy policy which starts using random actions and gradually starts using the predicted Q-Value as training progresses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkNlySgv0IYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eps_min = 0.1\n",
        "eps_max = 1.0\n",
        "eps_decay_steps = 2000000\n",
        "\n",
        "def epsilon_greedy(q_values, step):\n",
        "  epsilon = max(eps_min,\n",
        "                eps_max - ((eps_max - eps_min) * (step / eps_decay_steps)))\n",
        "  if np.random.rand() < epsilon:\n",
        "    return np.random.randint(n_actions)\n",
        "  return np.argmax(q_values)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}