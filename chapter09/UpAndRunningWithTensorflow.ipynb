{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UpAndRunningWithTensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lzNVJ-wo7T7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 9: Up and Running with Tensorflow\n",
        "\n",
        "## Creating Your First Graph and Running It in a Session"
      ]
    },
    {
      "metadata": {
        "id": "nD1u3EUF0Xgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A computational graph with Tensorflow. Despite the code's appearance,\n",
        "# this does not perform any computation.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(3, name='x')\n",
        "y = tf.Variable(4, name='y')\n",
        "f = (x * x * y) + y + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uW4yJGFK7-nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a6ba651-8bf8-47a7-b0f3-2013a72cd2d6"
      },
      "cell_type": "code",
      "source": [
        "# Running the computational graph in a Tensorflow Session.\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6_tfdkb586lT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7bfdab2-e619-4922-ab1f-65125baee986"
      },
      "cell_type": "code",
      "source": [
        "# Another way to execute the code above. It automatically closes the Session.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x.initializer.run() # Equivalent to tf.get_default_session().run(x.initial)\n",
        "  y.initializer.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRbV6a7l9_yC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "192d509d-673f-4009-b8fb-9e6d672f23d7"
      },
      "cell_type": "code",
      "source": [
        "# It is possible to initialize all variables automatically.\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "unmVd0HR_Ngu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4596084a-434b-4e7d-fc3a-60241f9d7946"
      },
      "cell_type": "code",
      "source": [
        "# InteractiveSession is useful for Jupyter notebooks because it sets itself\n",
        "# as the default session automatically.\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khaAWN84H_d5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Managing Graphs"
      ]
    },
    {
      "metadata": {
        "id": "saK6KqPQIA0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8855fc0c-5a9e-4cee-c857-73f287d69282"
      },
      "cell_type": "code",
      "source": [
        "# New Variables are always added to the default graph automatically.\n",
        "\n",
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "49iBtMnFIbTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b85a8a00-85ec-4488-8813-518ee656b64f"
      },
      "cell_type": "code",
      "source": [
        "# Below is the syntax for adding a variable to a graph that is not\n",
        "# the default graph.\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  x2 = tf.Variable(2)\n",
        "x2.graph is graph"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "cq12H7zJIqM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c5f4ea4-b0aa-4369-ab7c-2e943bca9212"
      },
      "cell_type": "code",
      "source": [
        "x2.graph is tf.get_default_graph()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "928KvF6FI1Wj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lifecycle of a Node Value"
      ]
    },
    {
      "metadata": {
        "id": "08C7UiPtJDXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dd7d3395-f203-4b2c-c4b1-fa0ac0de7003"
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow automatically detects the dependency chain between nodes of\n",
        "# the computation graph.\n",
        "\n",
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # detects that y dependes on x, which depends on w. So it evaluates\n",
        "  # w, then x, then y.\n",
        "  print(y.eval())\n",
        "  print(z.eval())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cm28n4klJ1qx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Regression with Tensorflow\n",
        "\n",
        "Tensorflow operates with multidimensional arrays called <i>tensors</i>. The Python API uses NumPy's `ndarray` class to represent tensors. The previous examples used a single scalar value for a tensor. Below is an example of a Tensorflow graph which operates on a 2D array performing linear regression. Recall that the optimal parameters for Linear Regression, $\\hat{\\theta}$ is given by\n",
        "\n",
        "$$ \\hat{\\theta} = \\left( \\mathbf{X}^T \\cdot \\mathbf{X} \\right)^{-1} \\cdot \\mathbf{X}^T \\cdot \\mathbf{y} $$\n",
        "\n",
        "where $\\mathbf{X}$, $\\mathbf{y}$ is the training set."
      ]
    },
    {
      "metadata": {
        "id": "gMiutHPJMRJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b3751e6c-1a6e-42b2-a4d5-a6f339857ee8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  theta_value = theta.eval()\n",
        "  print(theta_value)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.71037292e+01]\n",
            " [ 4.36282694e-01]\n",
            " [ 9.40542948e-03]\n",
            " [-1.06901854e-01]\n",
            " [ 6.43611908e-01]\n",
            " [-4.06625077e-06]\n",
            " [-3.78273334e-03]\n",
            " [-4.23094332e-01]\n",
            " [-4.36462164e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yksJvFBrOudI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementing Gradient Descent\n",
        "\n",
        "### Manually Computing the Gradients\n",
        "\n",
        "Below is an implementation of Batch Gradient Descent where we manually compute the gradients."
      ]
    },
    {
      "metadata": {
        "id": "CJFyn0sbPDw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "314ab22b-5c79-4c02-944f-c858226e53ce"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "scaled_housing_data_plus_bias = \\\n",
        "  StandardScaler().fit_transform(housing_data_plus_bias)\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "gradients = (2 / m) * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - (learning_rate * gradients))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 7.857343673706055\n",
            "Epoch: 100 MSE: 4.889010429382324\n",
            "Epoch: 200 MSE: 4.844444751739502\n",
            "Epoch: 300 MSE: 4.832682132720947\n",
            "Epoch: 400 MSE: 4.824571132659912\n",
            "Epoch: 500 MSE: 4.818718910217285\n",
            "Epoch: 600 MSE: 4.814482688903809\n",
            "Epoch: 700 MSE: 4.811415672302246\n",
            "Epoch: 800 MSE: 4.809193134307861\n",
            "Epoch: 900 MSE: 4.807580947875977\n",
            "[[ 0.16158223]\n",
            " [ 0.8162949 ]\n",
            " [ 0.13743171]\n",
            " [-0.20074166]\n",
            " [ 0.23470476]\n",
            " [ 0.00246572]\n",
            " [-0.04062242]\n",
            " [-0.77622837]\n",
            " [-0.7434166 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vDDqd0vDVEQy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using autodiff\n",
        "\n",
        "Below is an implementation of the same Batch Gradient Descent which uses Tensorflow's `gradients()` function to automatically compute the gradient of the cost function, MSE. This is useful when the function you are computing the gradient of is not a nice, analytic function like Linear Regression."
      ]
    },
    {
      "metadata": {
        "id": "9xgtl7ksWpDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e9a0afdb-a0cd-4df6-fe1b-04e3ae28b840"
      },
      "cell_type": "code",
      "source": [
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "gradients = tf.gradients(mse, [theta])[0]\n",
        "training_op = tf.assign(theta, theta - (learning_rate * gradients))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 6.112096309661865\n",
            "Epoch: 100 MSE: 5.016570568084717\n",
            "Epoch: 200 MSE: 4.953281879425049\n",
            "Epoch: 300 MSE: 4.912069320678711\n",
            "Epoch: 400 MSE: 4.88232946395874\n",
            "Epoch: 500 MSE: 4.860785484313965\n",
            "Epoch: 600 MSE: 4.845162868499756\n",
            "Epoch: 700 MSE: 4.833826541900635\n",
            "Epoch: 800 MSE: 4.825592041015625\n",
            "Epoch: 900 MSE: 4.819604873657227\n",
            "[[ 0.860028  ]\n",
            " [ 0.81243414]\n",
            " [ 0.15590912]\n",
            " [-0.15753306]\n",
            " [ 0.1831805 ]\n",
            " [ 0.00923728]\n",
            " [-0.04210306]\n",
            " [-0.6451549 ]\n",
            " [-0.6101564 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "brWx_N6NXPYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensorflow computes the gradients using <i>reverse-mode autodiff</i>, which is good for when there are a large number of inputs and a small number of outputs, which is generally the case for neural networks.\n",
        "\n",
        "### Using an Optimizer\n",
        "\n",
        "Below is an example of using an out-of-the-box Gradient Descent optimizer for the same Linear Regression task."
      ]
    },
    {
      "metadata": {
        "id": "cTTvAhTnX83n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ed3e0646-bbd6-478a-ad93-37a21df57654"
      },
      "cell_type": "code",
      "source": [
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 6.642418384552002\n",
            "Epoch: 100 MSE: 4.987947940826416\n",
            "Epoch: 200 MSE: 4.93607234954834\n",
            "Epoch: 300 MSE: 4.908919811248779\n",
            "Epoch: 400 MSE: 4.887845039367676\n",
            "Epoch: 500 MSE: 4.871248722076416\n",
            "Epoch: 600 MSE: 4.8581132888793945\n",
            "Epoch: 700 MSE: 4.847670078277588\n",
            "Epoch: 800 MSE: 4.839329242706299\n",
            "Epoch: 900 MSE: 4.832639217376709\n",
            "[[ 0.55270267]\n",
            " [ 0.96036196]\n",
            " [ 0.16497257]\n",
            " [-0.4719435 ]\n",
            " [ 0.4585294 ]\n",
            " [ 0.01061443]\n",
            " [-0.04602391]\n",
            " [-0.44017678]\n",
            " [-0.4240848 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F63XUjQNYMib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can also use the `tf.train.MomentumOptimizer` which converges much faster than the Gradient Descent optimizer. It takes an extra hyperparameter, `momentum`."
      ]
    }
  ]
}