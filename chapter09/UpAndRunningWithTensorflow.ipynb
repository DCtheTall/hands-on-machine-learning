{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UpAndRunningWithTensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzNVJ-wo7T7U",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 9: Up and Running with Tensorflow\n",
        "\n",
        "## Creating Your First Graph and Running It in a Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1u3EUF0Xgj",
        "colab_type": "code",
        "outputId": "5b9bd265-497f-47d6-e95e-6720cabb20d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# A computational graph with Tensorflow. Despite the code's appearance,\n",
        "# this does not perform any computation.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(3, name='x')\n",
        "y = tf.Variable(4, name='y')\n",
        "f = (x * x * y) + y + 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW4yJGFK7-nj",
        "colab_type": "code",
        "outputId": "5aac4229-5e43-492a-d975-fab5eefd2dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Running the computational graph in a Tensorflow Session.\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_tfdkb586lT",
        "colab_type": "code",
        "outputId": "a59ed18c-044f-41e4-95c9-5d54bf440efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Another way to execute the code above. It automatically closes the Session.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x.initializer.run() # Same as tf.get_default_session().run(x.initializer)\n",
        "  y.initializer.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRbV6a7l9_yC",
        "colab_type": "code",
        "outputId": "3603ee58-4655-42e9-eb56-b26eded9bcb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# It is possible to initialize all variables automatically.\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmVd0HR_Ngu",
        "colab_type": "code",
        "outputId": "d27c4d21-e5a2-4e01-9140-7836de9556ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# InteractiveSession is useful for Jupyter notebooks because it sets itself\n",
        "# as the default session automatically.\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khaAWN84H_d5",
        "colab_type": "text"
      },
      "source": [
        "## Managing Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saK6KqPQIA0X",
        "colab_type": "code",
        "outputId": "97710142-6876-4a06-8f21-c7bd517444a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# New Variables are always added to the default graph automatically.\n",
        "\n",
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49iBtMnFIbTV",
        "colab_type": "code",
        "outputId": "9798d2bf-3698-4987-fc07-1594ee655009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Below is the syntax for adding a variable to a graph that is not\n",
        "# the default graph.\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  x2 = tf.Variable(2)\n",
        "x2.graph is graph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq12H7zJIqM8",
        "colab_type": "code",
        "outputId": "ad9cc96e-5923-44fc-d4e1-b8f6e2c35a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2.graph is tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928KvF6FI1Wj",
        "colab_type": "text"
      },
      "source": [
        "## Lifecycle of a Node Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08C7UiPtJDXi",
        "colab_type": "code",
        "outputId": "01854b5d-128c-46ce-c995-e16e8866ea70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Tensorflow automatically detects the dependency chain between nodes of\n",
        "# the computation graph.\n",
        "\n",
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # detects that y dependes on x, which depends on w. So it evaluates\n",
        "  # w, then x, then y.\n",
        "  print(y.eval())\n",
        "  print(z.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm28n4klJ1qx",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression with Tensorflow\n",
        "\n",
        "Tensorflow operates with multidimensional arrays called <i>tensors</i>. The Python API uses NumPy's `ndarray` class to represent tensors. The previous examples used a single scalar value for a tensor. Below is an example of a Tensorflow graph which operates on a 2D array performing linear regression. Recall that the optimal parameters for Linear Regression, $\\hat{\\theta}$ is given by\n",
        "\n",
        "$$ \\hat{\\theta} = \\left( \\mathbf{X}^{\\,T} \\cdot \\mathbf{X} \\right)^{-1} \\cdot \\mathbf{X}^{\\,T} \\cdot \\mathbf{y} $$\n",
        "\n",
        "where $\\mathbf{X}$, $\\mathbf{y}$ is the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMiutHPJMRJO",
        "colab_type": "code",
        "outputId": "1ba427fb-0481-46ba-aba0-830a9db203b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  theta_value = theta.eval()\n",
        "  print(theta_value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-3.71037292e+01]\n",
            " [ 4.36282694e-01]\n",
            " [ 9.40542948e-03]\n",
            " [-1.06901854e-01]\n",
            " [ 6.43611908e-01]\n",
            " [-4.06625077e-06]\n",
            " [-3.78273334e-03]\n",
            " [-4.23094332e-01]\n",
            " [-4.36462164e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yksJvFBrOudI",
        "colab_type": "text"
      },
      "source": [
        "## Implementing Gradient Descent\n",
        "\n",
        "### Manually Computing the Gradients\n",
        "\n",
        "Below is an implementation of Batch Gradient Descent where we manually compute the gradients using symbolic differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJFyn0sbPDw_",
        "colab_type": "code",
        "outputId": "1b89f519-1012-4a6e-d235-4b365bad9bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def reset_graph(seed=42):\n",
        "  tf.reset_default_graph()\n",
        "  tf.set_random_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "scaled_housing_data = StandardScaler().fit_transform(housing.data)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "gradients = (2 / m) * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - (learning_rate * gradients))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 4.886683940887451\n",
            "Epoch: 100 MSE: 0.7432243227958679\n",
            "Epoch: 200 MSE: 0.6249350905418396\n",
            "Epoch: 300 MSE: 0.5958799123764038\n",
            "Epoch: 400 MSE: 0.5770407915115356\n",
            "Epoch: 500 MSE: 0.5633828043937683\n",
            "Epoch: 600 MSE: 0.5533661842346191\n",
            "Epoch: 700 MSE: 0.5459967851638794\n",
            "Epoch: 800 MSE: 0.5405601859092712\n",
            "Epoch: 900 MSE: 0.5365379452705383\n",
            "[[ 2.0685523e+00]\n",
            " [ 7.1990943e-01]\n",
            " [ 1.2918781e-01]\n",
            " [-2.5240867e-04]\n",
            " [ 6.0832255e-02]\n",
            " [ 7.1688474e-04]\n",
            " [-3.7869673e-02]\n",
            " [-9.2682320e-01]\n",
            " [-8.8190389e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDDqd0vDVEQy",
        "colab_type": "text"
      },
      "source": [
        "### Using autodiff\n",
        "\n",
        "Below is an implementation of the same Batch Gradient Descent which uses Tensorflow's `gradients()` function to automatically compute the gradient of the cost function, MSE. This is useful for approximating the gradient of non-analytic functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xgtl7ksWpDB",
        "colab_type": "code",
        "outputId": "d83aa24b-1e77-464a-ea28-97611da0dc73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "reset_graph()\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "gradients = tf.gradients(mse, [theta])[0]\n",
        "training_op = tf.assign(theta, theta - (learning_rate * gradients))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 12.408014297485352\n",
            "Epoch: 100 MSE: 0.7551968693733215\n",
            "Epoch: 200 MSE: 0.5420873761177063\n",
            "Epoch: 300 MSE: 0.5331699848175049\n",
            "Epoch: 400 MSE: 0.5305381417274475\n",
            "Epoch: 500 MSE: 0.5287963151931763\n",
            "Epoch: 600 MSE: 0.5275490283966064\n",
            "Epoch: 700 MSE: 0.5266497135162354\n",
            "Epoch: 800 MSE: 0.5260010957717896\n",
            "Epoch: 900 MSE: 0.5255332589149475\n",
            "[[ 2.0685525e+00]\n",
            " [ 8.1063598e-01]\n",
            " [ 1.2685776e-01]\n",
            " [-2.0784079e-01]\n",
            " [ 2.4839844e-01]\n",
            " [-1.3083885e-03]\n",
            " [-3.9607048e-02]\n",
            " [-8.5861272e-01]\n",
            " [-8.2600278e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brWx_N6NXPYy",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow computes the gradients using <i>reverse-mode autodiff</i>, which is good for when there are a large number of inputs and a small number of outputs, which is generally the case for neural networks.\n",
        "\n",
        "### Using an Optimizer\n",
        "\n",
        "Below is an example of using an out-of-the-box Gradient Descent optimizer for the same Linear Regression task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTTvAhTnX83n",
        "colab_type": "code",
        "outputId": "30627a48-3c3b-4d91-a578-f667ec39b65e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "reset_graph()\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 12.408014297485352\n",
            "Epoch: 100 MSE: 0.7551969289779663\n",
            "Epoch: 200 MSE: 0.5420873761177063\n",
            "Epoch: 300 MSE: 0.5331699848175049\n",
            "Epoch: 400 MSE: 0.5305381417274475\n",
            "Epoch: 500 MSE: 0.528796374797821\n",
            "Epoch: 600 MSE: 0.5275490283966064\n",
            "Epoch: 700 MSE: 0.5266497135162354\n",
            "Epoch: 800 MSE: 0.5260010957717896\n",
            "Epoch: 900 MSE: 0.5255332589149475\n",
            "[[ 2.0685525e+00]\n",
            " [ 8.1063598e-01]\n",
            " [ 1.2685776e-01]\n",
            " [-2.0784082e-01]\n",
            " [ 2.4839845e-01]\n",
            " [-1.3083923e-03]\n",
            " [-3.9607048e-02]\n",
            " [-8.5861272e-01]\n",
            " [-8.2600278e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F63XUjQNYMib",
        "colab_type": "text"
      },
      "source": [
        "You can also use the `tf.train.MomentumOptimizer` which converges much faster than the Gradient Descent optimizer. It takes an extra hyperparameter, `momentum`. An example implementation using this optimizer is below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnEVwOLoCQnf",
        "colab_type": "code",
        "outputId": "18c12314-d9be-4336-b3bc-3cb67db173f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "reset_graph()\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = \\\n",
        "  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {} MSE: {}'.format(epoch, mse.eval()))\n",
        "    sess.run(training_op)\n",
        "\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 MSE: 12.408014297485352\n",
            "Epoch: 100 MSE: 0.5252007246017456\n",
            "Epoch: 200 MSE: 0.5243331789970398\n",
            "Epoch: 300 MSE: 0.5243212580680847\n",
            "Epoch: 400 MSE: 0.5243210196495056\n",
            "Epoch: 500 MSE: 0.5243210196495056\n",
            "Epoch: 600 MSE: 0.5243210196495056\n",
            "Epoch: 700 MSE: 0.5243210196495056\n",
            "Epoch: 800 MSE: 0.5243210196495056\n",
            "Epoch: 900 MSE: 0.5243210196495056\n",
            "[[ 2.068558  ]\n",
            " [ 0.8296182 ]\n",
            " [ 0.11875145]\n",
            " [-0.265525  ]\n",
            " [ 0.3056947 ]\n",
            " [-0.00450307]\n",
            " [-0.03932622]\n",
            " [-0.8998881 ]\n",
            " [-0.87054336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cGMovbSCR-N",
        "colab_type": "text"
      },
      "source": [
        "## Feeding Data to the Training Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsAiGVfAd9d",
        "colab_type": "code",
        "outputId": "11a6a5c1-f72d-430b-fe92-d5647c8adf71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# An example of a placeholder node. Using None for a dimension means it can be\n",
        "# any size.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
        "B = A + 5\n",
        "with tf.Session() as sess:\n",
        "  # Calling eval with the feed_dict parameter to provide a value for the\n",
        "  # placeholder node, A.\n",
        "  B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
        "  B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
        "  print(B_val_1)\n",
        "  print(B_val_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6. 7. 8.]]\n",
            "[[ 9. 10. 11.]\n",
            " [12. 13. 14.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvM_6eIrDZN4",
        "colab_type": "text"
      },
      "source": [
        "### Mini-Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lKEf7KGDbHO",
        "colab_type": "code",
        "outputId": "aff1fd12-41a5-4207-b19b-4c5ea46b72b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "n_epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Setting up computation graph.\n",
        "reset_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = \\\n",
        "  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
        "training_op = optimizer.minimize(mse)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Mini-batch Gradient Descent.\n",
        "batch_size = 1000\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "def fetch_batch(epoch, batch_idx, batch_size):\n",
        "  np.random.seed((epoch * batch_size) + batch_idx)\n",
        "  indices = np.random.randint(m, size=batch_size)\n",
        "  X_batch = scaled_housing_data_plus_bias[indices]\n",
        "  y_batch = housing.target.reshape(-1, 1)[indices]\n",
        "  return X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    for batch_idx in range(n_batches):\n",
        "      X_batch, y_batch = fetch_batch(epoch, batch_idx, batch_size)\n",
        "      sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.0561285 ]\n",
            " [ 0.8382819 ]\n",
            " [ 0.11016789]\n",
            " [-0.25945365]\n",
            " [ 0.35881576]\n",
            " [-0.00353022]\n",
            " [-0.04197577]\n",
            " [-0.8903134 ]\n",
            " [-0.87608033]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqyxbuVCdRVb",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Restoring Models\n",
        "\n",
        "You can save your model parameters to disk to reuse later and you can even save your model during intervals while training in case your machine fails. Below is an example of code which does this using Tensorflow's `Saver` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZX4QL3Cf5QU",
        "colab_type": "code",
        "outputId": "58f70bc9-08b6-4c91-abcd-f812eab3501a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# This code trains a Linear Regression and saves the model after every\n",
        "# 100 epochs of training.\n",
        "\n",
        "n_epochs = 1000\n",
        "\n",
        "reset_graph()\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = \\\n",
        "  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
        "training_op = optimizer.minimize(mse)\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    if epoch % 100 == 0:\n",
        "      save_path = saver.save(sess, '/tmp/my_model.ckpt')\n",
        "    sess.run(training_op)\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.068558  ]\n",
            " [ 0.8296182 ]\n",
            " [ 0.11875145]\n",
            " [-0.265525  ]\n",
            " [ 0.3056947 ]\n",
            " [-0.00450307]\n",
            " [-0.03932622]\n",
            " [-0.8998881 ]\n",
            " [-0.87054336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P91cF8-QguLP",
        "colab_type": "code",
        "outputId": "e88cdc70-1188-4014-fcf0-aeae8765c469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# This code restores the model and remembers optimal weight vector.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, '/tmp/my_model.ckpt')\n",
        "  best_theta = theta.eval()\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/my_model.ckpt\n",
            "[[ 2.068558  ]\n",
            " [ 0.8296182 ]\n",
            " [ 0.11875145]\n",
            " [-0.265525  ]\n",
            " [ 0.3056947 ]\n",
            " [-0.00450307]\n",
            " [-0.03932622]\n",
            " [-0.8998881 ]\n",
            " [-0.87054336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRfkz4EhhvAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code creates a Saver instance which will only save the parameters for\n",
        "# one variable under a new name.\n",
        "\n",
        "saver = tf.train.Saver({'weights': theta})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Qz1aRYiMuR",
        "colab_type": "code",
        "outputId": "8c5d8e57-263d-4293-ff19-32dede15ae1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# You can save and restore the computation graph as well.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "saver = tf.train.import_meta_graph('/tmp/my_model.ckpt.meta')\n",
        "theta = tf.get_default_graph().get_tensor_by_name('theta:0')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, '/tmp/my_model.ckpt')\n",
        "  best_theta = theta.eval(session=sess)\n",
        "  print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/my_model.ckpt\n",
            "[[ 2.068558  ]\n",
            " [ 0.8296182 ]\n",
            " [ 0.11875145]\n",
            " [-0.265525  ]\n",
            " [ 0.3056947 ]\n",
            " [-0.00450307]\n",
            " [-0.03932622]\n",
            " [-0.8998881 ]\n",
            " [-0.87054336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaQTQYbnkNEf",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing the Graph and Training Curves Using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0CfJK6BkYqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code creates a log directory for Tensorflow to output the graph definition\n",
        "# and stats during training, such as the value of the MSE.\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
        "root_logdir = 'tf_logs'\n",
        "logdir = '{}/run-{}/'.format(root_logdir, now)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLVV7DgvlGlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the graph for Mini-batch Gradient Descent.\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "reset_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = \\\n",
        "  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
        "training_op = optimizer.minimize(mse)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Mini-batch Gradient Descent.\n",
        "batch_size = 1000\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cXRBjxvljYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adds a node to log the MSE.\n",
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "\n",
        "# Writes the graph definition to a file.\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTqBQFVjmhAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running the training job and outputting the summary results to log files.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    for batch_idx in range(n_batches):\n",
        "      X_batch, y_batch = fetch_batch(epoch, batch_idx, batch_size)\n",
        "      if batch_idx % 10 == 0:\n",
        "        summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        step = (epoch * n_batches) + batch_idx\n",
        "        file_writer.add_summary(summary_str, step)\n",
        "      sess.run(training_op, feed_dict={X: X_batch, y: y_batch})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Nx-o5dnVTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_nlCY_JncXo",
        "colab_type": "text"
      },
      "source": [
        "The following code allows you to run Tensorboard from Google colab using the tutorial found [here]()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0OITw_CnaQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzowUknXnxt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(root_logdir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX9YqTJen9sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgk3S2l7oCPg",
        "colab_type": "code",
        "outputId": "e2fa5f74-d4f2-473e-d115-d3a698c0b3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://755554ff.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRv-vzIYXWoE",
        "colab_type": "text"
      },
      "source": [
        "## Name Scopes\n",
        "\n",
        "It is possible to scope the names of graph nodes, which is useful for more complex graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "773u1yrsX8Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running the same graph above where the error and MSE nodes are\n",
        "# in a Tensorflow name scope.\n",
        "\n",
        "reset_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1., 1.), name='theta')\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "with tf.name_scope('loss') as scope:\n",
        "  error = y_pred - y\n",
        "  mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "optimizer = \\\n",
        "  tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
        "training_op = optimizer.minimize(mse)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp-RVoiadmT9",
        "colab_type": "code",
        "outputId": "5e6f8e76-f07d-49ff-db93-58b8eaf9b7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(error.op.name)\n",
        "print(mse.op.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss/sub\n",
            "loss/mse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI49qf5eeZ7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PSGvKOfdzJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 100\n",
        "batch_size = 1000\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(n_epochs):\n",
        "    for batch_idx in range(batch_size):\n",
        "      X_batch, y_batch = fetch_batch(epoch, batch_idx, batch_size)\n",
        "      if batch_idx % 10 == 0:\n",
        "        summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        step = (batch_size * epoch) + batch_idx\n",
        "        file_writer.add_summary(summary_str, step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXNVL9hUfvFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'.format(root_logdir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ6iyMrhfxNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhweuXZvfzg-",
        "colab_type": "code",
        "outputId": "cce3bf7b-fa10-4786-9179-bc268cb71a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ca199611.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gknu5nqilCa",
        "colab_type": "code",
        "outputId": "32d91df9-2a15-4239-935c-3df5a1bb7d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "a1 = tf.Variable(0, name='a')\n",
        "a2 = tf.Variable(1, name='a')\n",
        "\n",
        "print(a1.op.name)\n",
        "print(a2.op.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "a_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1zPupIWi3Q9",
        "colab_type": "code",
        "outputId": "9f143c33-f305-460b-8246-f45891c13af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.name_scope('param') as scope:\n",
        "  a3 = tf.Variable(0, name='a')\n",
        "\n",
        "with tf.name_scope('param') as scope:\n",
        "  a4 = tf.Variable(0, name='a')\n",
        "\n",
        "print(a3.op.name)\n",
        "print(a4.op.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param/a\n",
            "param_1/a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SMjWuUgdw4",
        "colab_type": "text"
      },
      "source": [
        "## Modularity\n",
        "\n",
        "Suppose you want to create a graph that adds the output of two <i>rectified linear units</i> (ReLU). A ReLU evaluates a linear function then returns the return value if it is positive, zero otherwise.\n",
        "\n",
        "$$ h_{\\mathbf{w},\\,b}(\\mathbf{X}) = \\max(\\mathbf{X} \\cdot \\mathbf{w} + b, 0) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNyIb4bijRA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal((n_features, 1)), name='weights1')\n",
        "w2 = tf.Variable(tf.random_normal((n_features, 1)), name='weights2')\n",
        "b1 = tf.Variable(0., name='bias1')\n",
        "b2 = tf.Variable(0., name='bias2')\n",
        "\n",
        "z1 = tf.add(tf.matmul(X, w1), b1, name='z1')\n",
        "z2 = tf.add(tf.matmul(X, w2), b2, name='z2')\n",
        "\n",
        "relu1 = tf.maximum(z1, 0., name='relu1')\n",
        "relu2 = tf.maximum(z2, 0., name='relu2')\n",
        "\n",
        "output = tf.add(relu1, relu2, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1y13l96mX56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow lets you modularize the repetitive process of computing ReLU\n",
        "# terms.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "  w_shape = (int(X.get_shape()[1]), 1)\n",
        "  w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "  b = tf.Variable(0., name='bias')\n",
        "  z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "  return tf.maximum(z, 0., name='relu')\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "relus = [relu(X) for _ in range(5)]\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRVXtBtqodYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer = tf.summary.FileWriter('logs/relu', tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBCnxvzonc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnkIFHrSoriq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6008 &'.format('logs/relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-8_hhT5ouUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6008 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLCIf2vbowgo",
        "colab_type": "code",
        "outputId": "65f5fa3d-43d3-4ede-96a4-44f29e79de06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://5427d72a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEqTYtOQsCje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Having the repeated nodes be defined in their own namespace helps simplify\n",
        "# the Tensorboard graph.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "  with tf.name_scope('relu'):\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "    b = tf.Variable(0., name='bias')\n",
        "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "    return tf.maximum(z, 0., name='relu')\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "relus = [relu(X) for _ in range(5)]\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZIIfCits1JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer = tf.summary.FileWriter('logs/relu', tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDeZenrAt6qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBZ5HUXUtyem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format('logs/relu'))\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92JE5SvRt0sN",
        "colab_type": "code",
        "outputId": "af93a149-caa2-4d91-d880-f3eb4e5afbc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://a13a7e81.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5nAH0zhrllz",
        "colab_type": "text"
      },
      "source": [
        "## Sharing Variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jczvXESIzOze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can share variables by passing them as parameters to the function\n",
        "# making the relu node.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def relu(X, threshold):\n",
        "  with tf.name_scope('relu'):\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "    b = tf.Variable(0., name='bias')\n",
        "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "    return tf.maximum(z, threshold, name='relu')\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "threshold = tf.Variable(0., name='threshold')\n",
        "relus = [relu(X, threshold) for _ in range(5)]\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UNA1Y_v0sVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One option is to add the shared variable as a property of the relu()\n",
        "# function.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "  with tf.name_scope('relu'):\n",
        "    if not hasattr(relu, 'threshold'):\n",
        "      relu.threshold = tf.Variable(0., name='threshold')\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "    b = tf.Variable(0., name='bias')\n",
        "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "    return tf.maximum(z, relu.threshold, name='relu')\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "relus = [relu(X) for _ in range(5)]\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi38WdFt20LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function defines the threshold variable using syntax which will throw\n",
        "# an Exception if the variable has been already created. This can be used\n",
        "# to prevent reusing variables.\n",
        "\n",
        "with tf.variable_scope('relu'):\n",
        "  threshold = \\\n",
        "    tf.get_variable('threshold', shape=(),\n",
        "                    initializer=tf.constant_initializer(0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLKbyOo64HXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will throw an exception if the threshold variable has not yet\n",
        "# been created or if it was not created with the get_variable() function.\n",
        "\n",
        "with tf.variable_scope('relu', reuse=True) as scope:\n",
        "  threshold = tf.get_variable('threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1clsJc6DJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is equivalent to the cell above.\n",
        "\n",
        "with tf.variable_scope('relu') as scope:\n",
        "  scope.reuse_variables()\n",
        "  threshold = tf.get_variable('threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flG1i4dd7Gxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following code is for the ReLU graph and reuses the threshold variable.\n",
        "\n",
        "reset_graph()\n",
        "n_features = 3\n",
        "\n",
        "def relu(X):\n",
        "  with tf.variable_scope('relu', reuse=True):\n",
        "    threshold = tf.get_variable('threshold')\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "    b = tf.Variable(0., name='bias')\n",
        "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "    return tf.maximum(z, threshold, name='relu')\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "with tf.variable_scope('relu'):\n",
        "  threshold = tf.get_variable('threshold', shape=(),\n",
        "                              initializer=tf.constant_initializer(0.))\n",
        "relus = [relu(X) for _ in range(5)]\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V7uxyJR-Ogr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Viewing the graph in Tensorboard.\n",
        "\n",
        "file_writer = tf.summary.FileWriter('logs/relu', tf.get_default_graph())\n",
        "file_writer.close()\n",
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'.format('logs/relu'))\n",
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpAhcUON-Vvv",
        "colab_type": "code",
        "outputId": "9284daba-3972-4837-f7d2-e2a7c97b3b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://fe37ee78.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCLITumN_YP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following code creates a graph indentical to the one that the previous\n",
        "# cell created, using a different syntax which allows threshold to be\n",
        "# initialized on the first call of relu().\n",
        "\n",
        "reset_graph()\n",
        "n_features = 3\n",
        "\n",
        "def relu(X):\n",
        "  threshold = tf.get_variable('threshold', shape=(),\n",
        "                              initializer=tf.constant_initializer(0.))\n",
        "  w_shape = (int(X.get_shape()[1]), 1)\n",
        "  w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
        "  b = tf.Variable(0., name='bias')\n",
        "  z = tf.add(tf.matmul(X, w), b, name='z')\n",
        "  return tf.maximum(z, threshold, name='relu')\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "relus = []\n",
        "for idx in range(5):\n",
        "  with tf.variable_scope('relu', reuse=(idx >= 1 or None)):\n",
        "    relus.append(relu(X))\n",
        "output = tf.add_n(relus, name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZskUetVHuoD",
        "colab_type": "text"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "### 1. What are the main advantages of creating a computation graph rather than directly executing the computations? What are the main drawbacks?\n",
        "\n",
        "The main advantage of creating a computation graph is that you get to create an abstract model of your computation before you execute it. This allows you to analyze the algorithm and model without necessarily running it. It also allows TensorFlow to handle execution of the graph for you, which lets you easily run the model in different threads or on multiple machines.\n",
        "\n",
        "The main drawback is that you have to maintain code which defines your computation as well as the code for actually executing the computation. It also makes the learning curve for TensorFlow steeper.\n",
        "\n",
        "### 2. Is the statement `a_val = e.eval(session=sess)` equivalent to `a_val = sess.run(a)`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFHOzNZzJqNl",
        "colab_type": "code",
        "outputId": "8628e1fb-20da-43d9-a118-627d65c66a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reset_graph()\n",
        "e = tf.constant(1., name='e')\n",
        "sess = tf.Session()\n",
        "print(e.eval(session=sess) == sess.run(e))\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnGmmsvJ7EM",
        "colab_type": "text"
      },
      "source": [
        "Yes, the two statements are equivalent to one another.\n",
        "\n",
        "### 3. Is the statement `a_val, b_val = a.eval(session=sess), b.eval(session=sess)` equivalent to `a_val, b_val = sess.run([a, b])`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNFXS0-8K0BF",
        "colab_type": "text"
      },
      "source": [
        "No, the statements are <i>not</i> equivalent. Although they have the same output, `a_val, b_val = a.eval(session=sess), b.eval(session=sess)` runs the graph twice. So if these nodes depended on nodes which change state, it can alter the output.\n",
        "\n",
        "### 4. Can you run two graphs in the same session?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y40AUFlOK0w_",
        "colab_type": "code",
        "outputId": "e402616b-1051-47f0-fdc0-0103d49ca477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reset_graph()\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  a = tf.constant(1., name='a')\n",
        "b = tf.constant(2., name='b')\n",
        "\n",
        "sess = tf.Session()\n",
        "try:\n",
        "  sess.run(a)\n",
        "  sess.run(b)\n",
        "  print('Possible.')\n",
        "except:\n",
        "  print('Not possible.')\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not possible.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVVEY4LtLgxW",
        "colab_type": "code",
        "outputId": "af76b54a-ba09-4ec6-df49-486f153abef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reset_graph()\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  a = tf.constant(1., name='a')\n",
        "b = tf.constant(2., name='b')\n",
        "\n",
        "with graph.as_default():\n",
        "  sess = tf.Session()\n",
        "  try:\n",
        "    sess.run(a)\n",
        "    sess.run(b)\n",
        "    print('Possible.')\n",
        "  except:\n",
        "    print('Not possible.')\n",
        "  sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not possible.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MovWRFwNLmxl",
        "colab_type": "text"
      },
      "source": [
        "No, it is not possible to run multiple graphs in the same session.\n",
        "\n",
        "### 5. If you create a graph, `g`, containing a variable, `w`, then start two threads and open a session in each thread, both using the same graph `g`, will each session have its own copy of the variable `w` or will it be shared?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6s6C4dMFog",
        "colab_type": "code",
        "outputId": "d420ea34-b1ee-4709-b086-b608ca1363fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# In this code, g is simply the default graph.\n",
        "\n",
        "from threading import Thread\n",
        "import time\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  w = tf.Variable(1., name='w')\n",
        "\n",
        "def first_session():\n",
        "  with g.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      w.initializer.run(session=sess)\n",
        "      tf.assign(w, 2.)\n",
        "      print('reassigned w')\n",
        "      time.sleep(10) # keep alive until after thread 2 is finished.\n",
        "    \n",
        "def second_session():\n",
        "  with g.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      w.initializer.run(session=sess)\n",
        "      time.sleep(5) # Wait for the 1st thread to execute the code before sleeping\n",
        "      print('evaluating w')\n",
        "      print(w.eval())\n",
        "    \n",
        "t1 = Thread(target=first_session, args=())\n",
        "t2 = Thread(target=second_session, args=())\n",
        "t1.start()\n",
        "t2.start()\n",
        "t1.join()\n",
        "t2.join()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reassigned w\n",
            "evaluating w\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jT-Nj_WPotM",
        "colab_type": "text"
      },
      "source": [
        "In local Tensorflow, the variable `w` will have its own value in each session, as the code above sows. In distributed Tensorflow, however, it is possible to share variables across sessions.\n",
        "\n",
        "### 6. When is a variable initialized? When is it destroyed?\n",
        "\n",
        "A variable is initialized when its or its initializer's `run()` method is invoked. It is destroyed when the session is closed. In distributed TensorFlow, variables persist in their containers even after a session ends, in order to destroy the variable you must delete the container.\n",
        "\n",
        "### 7. What is the difference between a placeholder and a variable?\n",
        "\n",
        "A placeholder is a node which has its value provided during the evaluation of other nodes which depend on the placeholder. In order to evaluate the nodes which depend on the placeholder, you <i>must</i> feed a value into it.\n",
        "\n",
        "Variables on the other hand store a default value in state. Although you <i>can</i> feed values to variable nodes during evaluation, it is not required.\n",
        "\n",
        "### 8. What happens when you run the graph to evaluate an operation that depends on a placeholder but you don't feed its value? What happens if the operation does not depend on the placeholder?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVOpNKwNQgWP",
        "colab_type": "code",
        "outputId": "9ebac944-6824-486e-d238-eeae713afc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluating a node which depends on a placeholder without feeding the\n",
        "# placeholder a value.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "a = tf.placeholder(tf.float32, shape=())\n",
        "b = 2 * a\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    b.eval()\n",
        "    print('Possible.')\n",
        "  except:\n",
        "    print('Not possible.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not possible.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuf8OimtR4DP",
        "colab_type": "code",
        "outputId": "6fee21ac-c30c-444f-df18-d469c4467eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluating a node which does not depend on the placeholder.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "a = tf.placeholder(tf.float32, shape=())\n",
        "b = tf.constant(2.)\n",
        "c = 2 * b\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    c.eval()\n",
        "    print('Possible.')\n",
        "  except:\n",
        "    print('Not possible.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13wxNVHjSMgI",
        "colab_type": "text"
      },
      "source": [
        "### 9. When you run a graph, can you feed the output value of any operation, or just the value of placeholders?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojPkQdbPSbKh",
        "colab_type": "code",
        "outputId": "46f684d1-6af2-4a25-ef35-4c473ba8b133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The following code shows it is possible to feed the value for variables.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "a = tf.Variable(2., name='a')\n",
        "b = 2 * a\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(b.eval(feed_dict={a: 3.}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSW4PDQtS8tl",
        "colab_type": "code",
        "outputId": "71d4f882-a60f-4a66-84b1-c1d7e19dbe12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The following code shows it is also possible to feed values to\n",
        "# nodes defined by operations on other nodes.\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "a = tf.Variable(2., name='a')\n",
        "b = 2 * a\n",
        "c = 3 + b\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(c.eval(feed_dict={b: 1.}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Eyawj3TW-4",
        "colab_type": "text"
      },
      "source": [
        "### 10. How can you set a variable to any value you want during the execution phase?\n",
        "\n",
        "You can either use `tf.assign()` to change the value of the variable, see the code for exercise 5 for an example.\n",
        "\n",
        "You can also feed the variable a value while evaluating a dependent node, see the code for exercise 9 for an example.\n",
        "\n",
        "### 11. How many times does reverse-mode autodiff need to traverse the graph to compute the gradients of the cost function with regards to 10 variables? What about forward-mode autodiff? And symbolic differentiation?\n",
        "\n",
        "Reverse-mode autodiff needs to travese the graph $n_\\text{outputs}+1$ times, which in this case is twice, since we are computing the gradient of a function which returns a scalar.\n",
        "\n",
        "Forward-mode autodiff requires $n_\\text{inputs}$ graph traversals, which in this case is 10, since we are differentiating the cost function with respect to 10 variables.\n",
        "\n",
        "Symbolic differentiation does not traverse the original graph, instead it requires us to define a new graph representing the gradient of the original cost function.\n",
        "\n",
        "### 12. Implement Logistic Regression with Mini-batch Gradient Descent using TensorFlow. Train it and evaluate it on the moons dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEJZuY20v_fl",
        "colab_type": "code",
        "outputId": "34a3aab4-abf2-4f7b-dafb-4978a01c1e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Importing the data and plotting it.\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_moons, y_moons = make_moons(n_samples=1000, random_state=42, noise=0.1)\n",
        "plt.scatter(X_moons[:,0], X_moons[:,1], c=y_moons)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nyFM4qqxH3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a bias term term to the inputs\n",
        "\n",
        "X_moons_plus_bias = np.c_[np.ones((X_moons.shape[0], 1)), X_moons]\n",
        "y_moons_reshaped = y_moons.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEQvgD0SkYCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the computational graph for Logistic Regression.\n",
        "\n",
        "root_logdir = 'log_reg'\n",
        "\n",
        "def logistic_regression(X, y, n_features, learning_rate=0.01, momentum=0.9):\n",
        "  with tf.name_scope('model'):\n",
        "    theta = tf.Variable(tf.random_uniform([n_features, 1], -1., 1.), name='theta')\n",
        "    y_proba = tf.math.sigmoid(tf.matmul(X, theta))\n",
        "  with tf.name_scope('train'):\n",
        "    loss = tf.losses.log_loss(y, y_proba)\n",
        "    optimizer = \\\n",
        "      tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "  with tf.name_scope('init'):\n",
        "    init = tf.global_variables_initializer()\n",
        "  now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
        "  logdir = '{}/run-{}/'.format(root_logdir, now)\n",
        "  with tf.name_scope('saver'):\n",
        "    loss_summary = tf.summary.scalar('Loss', loss)\n",
        "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
        "    saver = tf.train.Saver()\n",
        "  return y_proba, loss, training_op, init, loss_summary, file_writer, saver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkqFST1t1EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define procedure for training the data\n",
        "\n",
        "import os\n",
        "\n",
        "def fetch_batch(X_source, epoch, batch_size, batch_idx):\n",
        "  np.random.seed((epoch * batch_size) + batch_idx)\n",
        "  rand_idx = np.random.randint(X_moons_plus_bias.shape[0], size=batch_size)\n",
        "  return X_source[rand_idx], y_moons_reshaped[rand_idx]\n",
        "\n",
        "def save_model(saver, sess, model_path, epoch):\n",
        "  saver.save(sess, model_path)\n",
        "  with open('{}.epoch'.format(model_path), 'w') as f:\n",
        "    f.write(str(epoch))\n",
        "    f.close()\n",
        "\n",
        "def train_logistic_regression(X_source, initializer, n_epochs, n_batches,\n",
        "                              batch_size, training_op, X, y, model_path, saver,\n",
        "                              loss_summary, file_writer, y_proba):\n",
        "  with tf.Session() as sess:\n",
        "    if os.path.isfile(model_path):\n",
        "      saver.restore(sess, model_path)\n",
        "      with open('{}.epoch'.format(model_path)) as f:\n",
        "        start_epoch = int(f.read())\n",
        "    else:\n",
        "      sess.run(initializer)\n",
        "      start_epoch = 0\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "      if epoch % 10 == 0:\n",
        "        save_model(saver, sess, model_path, epoch)\n",
        "      for batch_idx in range(n_batches):\n",
        "        X_batch, y_batch = fetch_batch(X_source, epoch, batch_size, batch_idx)\n",
        "        if batch_idx % 10 == 0:\n",
        "          summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "          file_writer.add_summary(summary_str,\n",
        "                                  (epoch * batch_size) + batch_idx)\n",
        "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    save_model(saver, sess, model_path, n_epochs)\n",
        "    file_writer.close()\n",
        "    return y_proba.eval(feed_dict={X: X_source, y: y_moons_reshaped})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGgVBUj_28P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training a model and looking at the results\n",
        "\n",
        "n_features = X_moons_plus_bias.shape[1]\n",
        "\n",
        "reset_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "\n",
        "y_proba, loss, training_op, init, loss_summary, file_writer, saver = \\\n",
        "  logistic_regression(X, y, n_features)\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(X_moons_plus_bias.shape[0] / batch_size))\n",
        "\n",
        "y_proba_val = \\\n",
        "  train_logistic_regression(X_moons_plus_bias, init, n_epochs, n_batches,\n",
        "                            batch_size, training_op, X, y, 'tmp/log_reg.ckpt',\n",
        "                            saver, loss_summary, file_writer, y_proba)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li_l1uBNW3al",
        "colab_type": "code",
        "outputId": "8078c18f-bc61-42e9-f1b2-201262fc1b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Testing the accracy, precision, and recall on the training set.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "y_pred = (y_proba_val >= 0.5).flatten()\n",
        "print('Accuracy: {}'.format(accuracy_score(y_moons, y_pred)))\n",
        "print('Precision: {}'.format(precision_score(y_moons, y_pred)))\n",
        "print('Recall: {}'.format(recall_score(y_moons, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.877\n",
            "Precision: 0.8777555110220441\n",
            "Recall: 0.876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv87ewgLYu4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taking a look in Tensorboard\n",
        "\n",
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'.format(root_logdir))\n",
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T9V8KGFZYU4",
        "colab_type": "code",
        "outputId": "6edc435f-e75c-49a3-b182-5fe6e77ea13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://a4072b01.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUEVdELFYPb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trying to add polynomial features, since Logistic Regression is a linear\n",
        "# model and the moons dataset is very clearly nonlinear.\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X_moons_poly = PolynomialFeatures(degree=4).fit_transform(X_moons)\n",
        "X_moons_poly_plus_bias = np.c_[np.ones((X_moons_poly.shape[0], 1)),\n",
        "                               X_moons_poly]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7NqqsMgaKgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retraining the model with the new feature set.\n",
        "\n",
        "n_features = X_moons_poly_plus_bias.shape[1]\n",
        "\n",
        "reset_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "\n",
        "y_proba, loss, training_op, init, loss_summary, file_writer, saver = \\\n",
        "  logistic_regression(X, y, n_features)\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(X_moons_poly_plus_bias.shape[0] / batch_size))\n",
        "\n",
        "y_proba_val = \\\n",
        "  train_logistic_regression(X_moons_poly_plus_bias, init, n_epochs, n_batches,\n",
        "                            batch_size, training_op, X, y, 'tmp/log_reg2.ckpt',\n",
        "                            saver, loss_summary, file_writer, y_proba)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMOWCx0nbsnP",
        "colab_type": "code",
        "outputId": "34c7f9c2-b0ef-4cba-9886-7f84a7ab3b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Adding polynomial features improved the model greatly.\n",
        "\n",
        "y_pred = (y_proba_val >= 0.5).flatten()\n",
        "print('Accuracy: {}'.format(accuracy_score(y_moons, y_pred)))\n",
        "print('Precision: {}'.format(precision_score(y_moons, y_pred)))\n",
        "print('Recall: {}'.format(recall_score(y_moons, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.982\n",
            "Precision: 0.9781746031746031\n",
            "Recall: 0.986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSM8sKmRcvr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experimenting with different batch sizes and learning rates.\n",
        "\n",
        "from scipy.stats import uniform, reciprocal\n",
        "\n",
        "def search_parameters(n_iterations):\n",
        "  rand_batch_sizes = [int(r) for r in uniform.rvs(40, 60, size=n_iterations)]\n",
        "  rand_learning_rates = reciprocal.rvs(0.01, 0.1, size=n_iterations)\n",
        "  for it in range(n_iterations):\n",
        "    batch_size = rand_batch_sizes[it]\n",
        "    learning_rate = rand_learning_rates[it]\n",
        "    \n",
        "    print('Iteration: {}'.format(it))\n",
        "    print('Batch Size:', batch_size)\n",
        "    print('Learning Rate:', learning_rate)\n",
        "    print('-------')\n",
        "    \n",
        "    n_features = X_moons_poly_plus_bias.shape[1]\n",
        "\n",
        "    reset_graph()\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
        "    y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "\n",
        "    y_proba, loss, training_op, init, loss_summary, file_writer, saver = \\\n",
        "      logistic_regression(X, y, n_features, learning_rate)\n",
        "    \n",
        "    n_epochs = 100\n",
        "    n_batches = int(np.ceil(X_moons_poly_plus_bias.shape[0] / batch_size))\n",
        "\n",
        "    y_proba_val = \\\n",
        "      train_logistic_regression(X_moons_poly_plus_bias, init, n_epochs,\n",
        "                                n_batches, batch_size, training_op, X, y,\n",
        "                                'tmp/log_reg_search_{}.ckpt'.format(it), saver,\n",
        "                                loss_summary, file_writer, y_proba)\n",
        "    \n",
        "    y_pred = (y_proba_val >= 0.5).flatten()\n",
        "    print('Accuracy: {}'.format(accuracy_score(y_moons, y_pred)))\n",
        "    print('Precision: {}'.format(precision_score(y_moons, y_pred)))\n",
        "    print('Recall: {}'.format(recall_score(y_moons, y_pred)))\n",
        "    print('======')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSMY8SkfZeY",
        "colab_type": "code",
        "outputId": "8fcd7385-8216-44fc-a400-c7b809a35b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "search_parameters(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Batch Size: 61\n",
            "Learning Rate: 0.07072597620496644\n",
            "-------\n",
            "Accuracy: 0.998\n",
            "Precision: 0.9960159362549801\n",
            "Recall: 1.0\n",
            "======\n",
            "Iteration: 1\n",
            "Batch Size: 74\n",
            "Learning Rate: 0.06647624407312398\n",
            "-------\n",
            "Accuracy: 0.998\n",
            "Precision: 0.9960159362549801\n",
            "Recall: 1.0\n",
            "======\n",
            "Iteration: 2\n",
            "Batch Size: 44\n",
            "Learning Rate: 0.04493194233490411\n",
            "-------\n",
            "Accuracy: 0.998\n",
            "Precision: 0.9960159362549801\n",
            "Recall: 1.0\n",
            "======\n",
            "Iteration: 3\n",
            "Batch Size: 77\n",
            "Learning Rate: 0.028212149592946142\n",
            "-------\n",
            "Accuracy: 0.989\n",
            "Precision: 0.9860834990059643\n",
            "Recall: 0.992\n",
            "======\n",
            "Iteration: 4\n",
            "Batch Size: 70\n",
            "Learning Rate: 0.016721593511578182\n",
            "-------\n",
            "Accuracy: 0.985\n",
            "Precision: 0.9840319361277445\n",
            "Recall: 0.986\n",
            "======\n",
            "Iteration: 5\n",
            "Batch Size: 43\n",
            "Learning Rate: 0.07933213656615368\n",
            "-------\n",
            "Accuracy: 0.998\n",
            "Precision: 0.9960159362549801\n",
            "Recall: 1.0\n",
            "======\n",
            "Iteration: 6\n",
            "Batch Size: 84\n",
            "Learning Rate: 0.0331489463665092\n",
            "-------\n",
            "Accuracy: 0.99\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "======\n",
            "Iteration: 7\n",
            "Batch Size: 98\n",
            "Learning Rate: 0.015446215925526047\n",
            "-------\n",
            "Accuracy: 0.978\n",
            "Precision: 0.9760956175298805\n",
            "Recall: 0.98\n",
            "======\n",
            "Iteration: 8\n",
            "Batch Size: 95\n",
            "Learning Rate: 0.09793523281245232\n",
            "-------\n",
            "Accuracy: 0.998\n",
            "Precision: 0.9960159362549801\n",
            "Recall: 1.0\n",
            "======\n",
            "Iteration: 9\n",
            "Batch Size: 44\n",
            "Learning Rate: 0.02239920197092227\n",
            "-------\n",
            "Accuracy: 0.997\n",
            "Precision: 0.9940357852882704\n",
            "Recall: 1.0\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}